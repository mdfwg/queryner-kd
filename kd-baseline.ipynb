{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f76da3c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "522181e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2b0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, label_pad_id=-100, max_length=128):\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw = json.load(f)[\"examples\"]\n",
    "        self.data = raw\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_pad_id = label_pad_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx][\"tokens\"]\n",
    "        ner_tags = self.data[idx][\"ner_tags\"]\n",
    "\n",
    "        # buat encoding untuk tokens \n",
    "        encoding = self.tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # align labels dengan tokens yang sudah diencoding (jadi kepotong2 sesuai tokenization)\n",
    "        word_ids = encoding.word_ids(batch_index=0)\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80a7c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_info(model_name):\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    id2label = config.id2label\n",
    "    label2id = config.label2id\n",
    "    num_labels = config.num_labels\n",
    "\n",
    "    label_info = {\n",
    "        \"id2label\": id2label,\n",
    "        \"label2id\": label2id,\n",
    "        \"num_labels\": num_labels\n",
    "    }\n",
    "\n",
    "    return label_info\n",
    "\n",
    "def create_dataloaders(\n",
    "        train_path, val_path, test_path,\n",
    "        model_name,\n",
    "        batch_size=32,\n",
    "        max_length=128\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_dataset = NERDataset(train_path, tokenizer, max_length=max_length)\n",
    "    val_dataset = NERDataset(val_path, tokenizer, max_length=max_length)\n",
    "    test_dataset = NERDataset(test_path, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34497ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\train.json\",\n",
    "    val_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\validation.json\",\n",
    "    test_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\test.json\",\n",
    "    model_name=\"bltlab/queryner-augmented-data-bert-base-uncased\",\n",
    "    batch_size=16,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "label_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412972f",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1336c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers import AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2c0d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFOutputLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_labels):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, num_labels)\n",
    "        self.crf = CRF(num_tags=num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, outputs, labels=None, mask=None):\n",
    "        emissions = self.fc(outputs)\n",
    "\n",
    "        if labels is not None:\n",
    "            # CRF requires first token to be valid, so we create a modified mask\n",
    "            # that ensures first token is always included\n",
    "            if mask is None:\n",
    "                mask = torch.ones_like(labels, dtype=torch.bool)\n",
    "            else:\n",
    "                mask = mask.bool()\n",
    "            \n",
    "            # Ensure first position is always valid for CRF\n",
    "            mask[:, 0] = True\n",
    "            \n",
    "            # Replace -100 with 0 (dummy label) to avoid index issues\n",
    "            labels_crf = labels.clone()\n",
    "            labels_crf[labels == -100] = 0\n",
    "            \n",
    "            # Calculate loss\n",
    "            log_likelihood = self.crf(emissions, tags=labels_crf, mask=mask, reduction=\"mean\")\n",
    "            loss = -log_likelihood\n",
    "            return {\"logits\": emissions, \"loss\": loss}\n",
    "        else:\n",
    "            if mask is None:\n",
    "                mask = torch.ones(outputs.shape[:2], dtype=torch.bool, device=outputs.device)\n",
    "            pred = self.crf.decode(emissions, mask=mask.bool())\n",
    "            return {\"logits\": emissions, \"pred\": pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0860ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNERModel(nn.Module):\n",
    "    def __init__(self, num_labels, use_crf=False):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.use_crf = use_crf\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        raise NotImplementedError(\"Forward method must be implemented in subclass.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c94df923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryNERTeacher(BaseNERModel):\n",
    "    def __init__(self, model_name, label_info, use_crf=False):\n",
    "        super().__init__(num_labels=label_info[\"num_labels\"], use_crf=use_crf)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            id2label=label_info[\"id2label\"],\n",
    "            label2id=label_info[\"label2id\"]\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.config.num_labels)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
    "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d21a7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERTStudent(BaseNERModel):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", label_info=None, use_crf=False):\n",
    "        self.use_crf = use_crf\n",
    "        self.num_labels = label_info[\"num_labels\"]\n",
    "        super().__init__(num_labels=self.num_labels, use_crf=self.use_crf)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            id2label=label_info[\"id2label\"],\n",
    "            label2id=label_info[\"label2id\"]\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6510b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyBertStudent(BaseNERModel):\n",
    "    def __init__(self, model_name=\"huawei-noah/TinyBERT_General_4L_312D\", label_info=None, use_crf=False):\n",
    "        self.use_crf = use_crf\n",
    "        self.num_labels = label_info[\"num_labels\"]\n",
    "        super().__init__(num_labels=self.num_labels, use_crf=self.use_crf)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            id2label=label_info[\"id2label\"],\n",
    "            label2id=label_info[\"label2id\"]\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a01e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMStudent(BaseNERModel):\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_labels, \n",
    "            use_crf=False,\n",
    "            model_name_for_vocab = 'bert-base-uncased',\n",
    "            emb_dim = 300,\n",
    "            lstm_hidden = 300,\n",
    "            label_info = None,\n",
    "            pad_token_id = 0\n",
    "        ):\n",
    "        super().__init__(num_labels, use_crf)\n",
    "        self.use_crf = use_crf\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_name_for_vocab)\n",
    "        vocab_size = config.vocab_size\n",
    "        pad_token_id = config.pad_token_id\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_token_id)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.classifier = nn.Linear(lstm_hidden * 2, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(hidden_dim=lstm_hidden * 2, num_labels=num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        emb = self.embedding(input_ids)\n",
    "        emb = self.dropout(emb)\n",
    "        outputs, _ = self.lstm(emb)\n",
    "        sequence_output = outputs\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ac6c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = QueryNERTeacher(model_name=\"bltlab/queryner-augmented-data-bert-base-uncased\", label_info=label_info, use_crf=False)\n",
    "student = DistilBERTStudent(model_name=\"distilbert-base-uncased\", label_info=label_info, use_crf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0af48f",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38f00f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c3f6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/training/kd_trainer.py\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    return F.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "def kl_divergence_loss(student_logits, teacher_logits, temperature):\n",
    "    p_teacher = F.log_softmax(teacher_logits / temperature, dim=-1)\n",
    "    p_student = F.softmax(student_logits / temperature, dim=-1)\n",
    "    loss = F.kl_div(p_teacher, p_student, reduction='batchmean')\n",
    "    loss = loss * (temperature ** 2)\n",
    "    return loss\n",
    "\n",
    "def kl_divergence_loss_masked(student_logits, teacher_logits, temperature, mask=None, eps=1e-12):\n",
    "    T = float(temperature)\n",
    "\n",
    "    student_log_prob = F.log_softmax(student_logits / T, dim=-1)   # (B, L, C)\n",
    "    teacher_prob = F.softmax(teacher_logits / T, dim=-1)           # (B, L, C)\n",
    "\n",
    "    kl_elem = F.kl_div(student_log_prob, teacher_prob, reduction='none')  # (B, L, C)\n",
    "\n",
    "    kl_token = kl_elem.sum(dim=-1)  # (B, L)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.bool()\n",
    "        valid_sum = mask.float().sum()\n",
    "        if valid_sum.item() == 0:\n",
    "            return torch.tensor(0.0, device=student_logits.device)\n",
    "        kl_sum = (kl_token * mask.float()).sum()\n",
    "        return (kl_sum / valid_sum) * (T * T)\n",
    "    else:\n",
    "        return kl_token.mean() * (T * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6a4ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/training/kd_trainer.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def kl_divergence_loss_masked(student_logits, teacher_logits, temperature, mask=None, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute masked KL divergence loss for knowledge distillation.\n",
    "    \n",
    "    Args:\n",
    "        student_logits: (B, L, C) logits from student\n",
    "        teacher_logits: (B, L, C) logits from teacher\n",
    "        temperature: Temperature for softening distributions\n",
    "        mask: (B, L) attention mask (1 for valid tokens)\n",
    "        eps: Small constant for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        Scalar loss value\n",
    "    \"\"\"\n",
    "    T = float(temperature)\n",
    "\n",
    "    student_log_prob = F.log_softmax(student_logits / T, dim=-1)   # (B, L, C)\n",
    "    teacher_prob = F.softmax(teacher_logits / T, dim=-1)           # (B, L, C)\n",
    "\n",
    "    kl_elem = F.kl_div(student_log_prob, teacher_prob, reduction='none')  # (B, L, C)\n",
    "    kl_token = kl_elem.sum(dim=-1)  # (B, L)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.bool()\n",
    "        valid_sum = mask.float().sum()\n",
    "        if valid_sum.item() == 0:\n",
    "            return torch.tensor(0.0, device=student_logits.device)\n",
    "        kl_sum = (kl_token * mask.float()).sum()\n",
    "        return (kl_sum / valid_sum) * (T * T)\n",
    "    else:\n",
    "        return kl_token.mean() * (T * T)\n",
    "\n",
    "\n",
    "def _to_tensor_preds(preds, batch_size, seq_len, device):\n",
    "    \"\"\"\n",
    "    Convert CRF decode output (list[list[int]] or list of tensors) into a tensor\n",
    "    of shape (batch_size, seq_len) padded with 0s. Caller must mask invalid tokens.\n",
    "    \"\"\"\n",
    "    pred_tensor = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n",
    "    for i, p in enumerate(preds):\n",
    "        if isinstance(p, torch.Tensor):\n",
    "            p = p.tolist()\n",
    "        L = len(p)\n",
    "        if L > 0:\n",
    "            pred_tensor[i, :L] = torch.tensor(p, dtype=torch.long, device=device)\n",
    "    return pred_tensor\n",
    "\n",
    "\n",
    "def _safe_get_pred_tensor(output, batch_size, seq_len, device):\n",
    "    \"\"\"\n",
    "    Return a (batch, seq_len) tensor of predictions from model output.\n",
    "    Handles:\n",
    "      - output[\"pred\"] is a tensor (batch, seq_len)\n",
    "      - output[\"pred\"] is a list of lists (per-seq predicted label ids)\n",
    "      - output has no \"pred\" (use logits.argmax)\n",
    "    \"\"\"\n",
    "    if \"pred\" in output:\n",
    "        pred = output[\"pred\"]\n",
    "        if isinstance(pred, torch.Tensor):\n",
    "            return pred.to(device)\n",
    "        else:\n",
    "            # assume list of lists\n",
    "            return _to_tensor_preds(pred, batch_size, seq_len, device)\n",
    "    elif \"logits\" in output:\n",
    "        return output[\"logits\"].argmax(dim=-1).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"No 'pred' or 'logits' in model output to produce predictions.\")\n",
    "\n",
    "\n",
    "def _accumulate_confusion_counts(preds_flat, labels_flat):\n",
    "    \"\"\"\n",
    "    Compute per-class TP, predicted_counts, actual_counts using vectors.\n",
    "    preds_flat and labels_flat are 1D torch.Long tensors on CPU or device.\n",
    "    Returns (tp_sum, pred_sum, actual_sum) and also total_tp, total_pred, total_actual per class sums.\n",
    "    \"\"\"\n",
    "    if preds_flat.numel() == 0:\n",
    "        return 0, 0, 0, None  # no valid tokens in this batch\n",
    "\n",
    "    max_label = int(max(int(preds_flat.max().item()), int(labels_flat.max().item())))\n",
    "    num_classes = max_label + 1\n",
    "\n",
    "    # compute per-class counts\n",
    "    tp_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n",
    "    pred_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n",
    "    actual_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        pred_mask = preds_flat == c\n",
    "        lab_mask = labels_flat == c\n",
    "        tp_per_class[c] = int((pred_mask & lab_mask).sum().item())\n",
    "        pred_per_class[c] = int(pred_mask.sum().item())\n",
    "        actual_per_class[c] = int(lab_mask.sum().item())\n",
    "\n",
    "    tp_sum = int(tp_per_class.sum().item())\n",
    "    pred_sum = int(pred_per_class.sum().item())\n",
    "    actual_sum = int(actual_per_class.sum().item())\n",
    "\n",
    "    return tp_sum, pred_sum, actual_sum, (tp_per_class.cpu().numpy(), pred_per_class.cpu().numpy(), actual_per_class.cpu().numpy())\n",
    "\n",
    "\n",
    "def _batch_metrics(pred_tensor, label_tensor, attention_mask):\n",
    "    \"\"\"\n",
    "    pred_tensor: (B, L)\n",
    "    label_tensor: (B, L) with -100 for ignored positions\n",
    "    attention_mask: (B, L) with 1 for valid tokens\n",
    "    Returns TP, predicted_count, actual_count (ints)\n",
    "    \"\"\"\n",
    "    mask = attention_mask.bool()\n",
    "    # also ensure labels not equal to -100 in valid positions\n",
    "    valid = mask & (label_tensor != -100)\n",
    "    if valid.sum().item() == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    preds_flat = pred_tensor[valid].view(-1)\n",
    "    labels_flat = label_tensor[valid].view(-1)\n",
    "\n",
    "    tp_sum, pred_sum, actual_sum, _ = _accumulate_confusion_counts(preds_flat, labels_flat)\n",
    "    return tp_sum, pred_sum, actual_sum\n",
    "\n",
    "\n",
    "def _final_metrics(tp_sum, pred_sum, actual_sum):\n",
    "    \"\"\"\n",
    "    Compute micro precision, recall, f1 from aggregated counts.\n",
    "    \"\"\"\n",
    "    precision = tp_sum / pred_sum if pred_sum > 0 else 0.0\n",
    "    recall = tp_sum / actual_sum if actual_sum > 0 else 0.0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "class KDTrainer:\n",
    "    \"\"\"\n",
    "    Trainer for both baseline (fine-tuning) and knowledge distillation.\n",
    "    \n",
    "    For baseline:\n",
    "        teacher_model=None, alpha=0, beta=1\n",
    "    \n",
    "    For KD:\n",
    "        teacher_model=<trained_model>, alpha=0.5, beta=0.5\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        teacher_model,\n",
    "        student_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler=None,\n",
    "        device=\"cuda\",\n",
    "        alpha=0.5,\n",
    "        beta=0.5,\n",
    "        temperature=2.0,\n",
    "        scheduler_type=\"plateau\"  # \"plateau\", \"cosine\", \"step\", or None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            teacher_model: Teacher model (None for baseline)\n",
    "            student_model: Student model to train\n",
    "            train_loader: Training DataLoader\n",
    "            val_loader: Validation DataLoader\n",
    "            optimizer: Optimizer for student model\n",
    "            scheduler: Learning rate scheduler (optional)\n",
    "            device: Device to use\n",
    "            alpha: Weight for KD loss (0 for baseline)\n",
    "            beta: Weight for student loss (1 for baseline)\n",
    "            temperature: Temperature for KD\n",
    "            scheduler_type: Type of scheduler for proper step() call\n",
    "        \"\"\"\n",
    "        self.student = student_model.to(device)\n",
    "        self.teacher = None  # ← FIX: Initialize to None\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_type = scheduler_type\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.T = temperature\n",
    "\n",
    "        # Setup teacher if provided\n",
    "        if teacher_model is not None:\n",
    "            self.teacher = teacher_model.to(device)\n",
    "            self.teacher.eval()  # Set to eval mode\n",
    "            for p in self.teacher.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Validate configuration\n",
    "        if self.alpha > 0 and self.teacher is None:\n",
    "            raise ValueError(\"alpha > 0 requires a teacher model!\")\n",
    "        \n",
    "        # Print training mode\n",
    "        mode = \"BASELINE\" if self.teacher is None else \"KNOWLEDGE DISTILLATION\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Mode: {mode}\")\n",
    "        print(f\"Alpha (KD loss weight): {self.alpha}\")\n",
    "        print(f\"Beta (Student loss weight): {self.beta}\")\n",
    "        print(f\"Temperature: {self.T}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    def compute_losses(self, batch):\n",
    "        \"\"\"\n",
    "        Compute losses for one batch.\n",
    "        \n",
    "        Returns:\n",
    "            loss_total: Combined loss\n",
    "            loss_kd: KD loss (0 if no teacher)\n",
    "            loss_student: Student task loss\n",
    "            pred_tensor: Predictions for metrics\n",
    "            labels: Ground truth labels\n",
    "            attention_mask: Attention mask\n",
    "        \"\"\"\n",
    "        input_ids = batch[\"input_ids\"].to(self.device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "        labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "\n",
    "        # Get teacher logits if needed\n",
    "        teacher_logits = None\n",
    "        if self.alpha > 0 and self.teacher is not None:\n",
    "            with torch.no_grad():\n",
    "                self.teacher.eval()\n",
    "                teacher_out = self.teacher(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "                teacher_logits = teacher_out[\"logits\"]\n",
    "\n",
    "        # Get student outputs\n",
    "        student_out = self.student(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "        student_logits = student_out[\"logits\"]\n",
    "\n",
    "        # Compute KD loss if teacher provided\n",
    "        if teacher_logits is not None:\n",
    "            loss_kd = kl_divergence_loss_masked(\n",
    "                student_logits, \n",
    "                teacher_logits, \n",
    "                self.T, \n",
    "                mask=attention_mask\n",
    "            )\n",
    "        else:\n",
    "            loss_kd = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        # Get student task loss\n",
    "        loss_student = student_out.get(\"loss\", torch.tensor(0.0, device=self.device))\n",
    "\n",
    "        # Combined loss\n",
    "        loss_total = self.alpha * loss_kd + self.beta * loss_student\n",
    "\n",
    "        # Get predictions for metrics\n",
    "        pred_tensor = _safe_get_pred_tensor(student_out, batch_size, seq_len, self.device)\n",
    "\n",
    "        return loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.student.train()\n",
    "        total_loss, total_kd, total_stu = 0.0, 0.0, 0.0\n",
    "        tp_acc, pred_acc, actual_acc = 0, 0, 0\n",
    "\n",
    "        for batch in tqdm(self.train_loader, desc=\"Training\"):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask = \\\n",
    "                self.compute_losses(batch)\n",
    "            \n",
    "            loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += float(loss_total.item())\n",
    "            total_kd += float(loss_kd.item())\n",
    "            total_stu += float(loss_student.item()) if isinstance(loss_student, torch.Tensor) else float(loss_student)\n",
    "\n",
    "            tp, pred_count, actual_count = _batch_metrics(pred_tensor, labels, attention_mask)\n",
    "            tp_acc += tp\n",
    "            pred_acc += pred_count\n",
    "            actual_acc += actual_count\n",
    "\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        avg_kd = total_kd / len(self.train_loader)\n",
    "        avg_stu = total_stu / len(self.train_loader)\n",
    "\n",
    "        # Update scheduler if provided\n",
    "        if self.scheduler:\n",
    "            if self.scheduler_type == \"plateau\":\n",
    "                self.scheduler.step(avg_loss)\n",
    "            else:\n",
    "                # For cosine, step, etc. that don't need metrics\n",
    "                self.scheduler.step()\n",
    "\n",
    "        precision, recall, f1 = _final_metrics(tp_acc, pred_acc, actual_acc)\n",
    "        return avg_loss, avg_kd, avg_stu, precision, recall, f1\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validate on validation set.\"\"\"\n",
    "        self.student.eval()\n",
    "        total_loss, total_kd, total_stu = 0.0, 0.0, 0.0\n",
    "        tp_acc, pred_acc, actual_acc = 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask = \\\n",
    "                    self.compute_losses(batch)\n",
    "                \n",
    "                total_loss += float(loss_total.item())\n",
    "                total_kd += float(loss_kd.item())\n",
    "                total_stu += float(loss_student.item()) if isinstance(loss_student, torch.Tensor) else float(loss_student)\n",
    "\n",
    "                tp, pred_count, actual_count = _batch_metrics(pred_tensor, labels, attention_mask)\n",
    "                tp_acc += tp\n",
    "                pred_acc += pred_count\n",
    "                actual_acc += actual_count\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        avg_kd = total_kd / len(self.val_loader)\n",
    "        avg_stu = total_stu / len(self.val_loader)\n",
    "\n",
    "        precision, recall, f1 = _final_metrics(tp_acc, pred_acc, actual_acc)\n",
    "        return avg_loss, avg_kd, avg_stu, precision, recall, f1\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        \"\"\"\n",
    "        Train for multiple epochs.\n",
    "        \n",
    "        Args:\n",
    "            num_epochs: Number of epochs to train\n",
    "            \n",
    "        Returns:\n",
    "            history: Dictionary containing training history\n",
    "        \"\"\"\n",
    "        history = {\n",
    "            \"train_loss\": [], \"val_loss\": [],\n",
    "            \"train_kd\": [], \"val_kd\": [],\n",
    "            \"train_stu\": [], \"val_stu\": [],\n",
    "            \"train_precision\": [], \"train_recall\": [], \"train_f1\": [],\n",
    "            \"val_precision\": [], \"val_recall\": [], \"val_f1\": []\n",
    "        }\n",
    "\n",
    "        best_val_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"EPOCH {epoch}/{num_epochs}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            train_loss, train_kd, train_stu, train_prec, train_rec, train_f1 = self.train_epoch()\n",
    "            val_loss, val_kd, val_stu, val_prec, val_rec, val_f1 = self.validate()\n",
    "\n",
    "            print(f\"\\nTrain Loss: {train_loss:.4f} (KD: {train_kd:.4f}, Student: {train_stu:.4f})\")\n",
    "            print(f\"Val Loss:   {val_loss:.4f} (KD: {val_kd:.4f}, Student: {val_stu:.4f})\")\n",
    "            print(f\"\\nTrain Metrics -> P: {train_prec:.4f}, R: {train_rec:.4f}, F1: {train_f1:.4f}\")\n",
    "            print(f\"Val Metrics   -> P: {val_prec:.4f}, R: {val_rec:.4f}, F1: {val_f1:.4f}\")\n",
    "            \n",
    "            # Track best validation F1\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                print(f\"✓ New best Val F1: {best_val_f1:.4f}\")\n",
    "\n",
    "            # Store history\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_kd\"].append(train_kd)\n",
    "            history[\"train_stu\"].append(train_stu)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_kd\"].append(val_kd)\n",
    "            history[\"val_stu\"].append(val_stu)\n",
    "\n",
    "            history[\"train_precision\"].append(train_prec)\n",
    "            history[\"train_recall\"].append(train_rec)\n",
    "            history[\"train_f1\"].append(train_f1)\n",
    "            history[\"val_precision\"].append(val_prec)\n",
    "            history[\"val_recall\"].append(val_rec)\n",
    "            history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Complete!\")\n",
    "        print(f\"Best Val F1: {best_val_f1:.4f}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0467f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one batch diagnostic\n",
    "batch = next(iter(train_loader))\n",
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "labels = batch[\"labels\"]\n",
    "\n",
    "# forward student (no KD/teacher)\n",
    "out = student(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "logits = out[\"logits\"]\n",
    "loss = out.get(\"loss\", None)\n",
    "\n",
    "# count valid tokens\n",
    "valid_mask = (attention_mask.bool()) & (labels != -100)\n",
    "num_valid = valid_mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b815c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1143, -0.2218,  0.1262,  ..., -0.1069,  0.2699, -0.1671],\n",
      "        [-0.1747, -0.3804,  0.2549,  ..., -0.3591,  0.1842,  0.0710],\n",
      "        [-0.4831, -0.2506,  0.4335,  ..., -0.3707,  0.0520,  0.2112],\n",
      "        ...,\n",
      "        [-0.0063, -0.1429,  0.0920,  ..., -0.0759,  0.0116, -0.0576],\n",
      "        [-0.0807, -0.0690, -0.0154,  ..., -0.1664, -0.0500,  0.0161],\n",
      "        [-0.1625,  0.0667, -0.1272,  ...,  0.0073, -0.2190, -0.0056]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([-100,    9, -100,  ..., -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "print(logits.view(-1, 35))\n",
    "print(labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "187c72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size, seq_len: torch.Size([16, 128])\n",
      "num_valid_tokens: 60\n",
      "raw loss scalar: 3.5641229152679443\n",
      "loss per valid token: 0.05940204858779907\n"
     ]
    }
   ],
   "source": [
    "print(\"batch_size, seq_len:\", input_ids.shape)\n",
    "print(\"num_valid_tokens:\", num_valid)\n",
    "\n",
    "if loss is not None:\n",
    "    print(\"raw loss scalar:\", float(loss.item()))\n",
    "    if num_valid > 0:\n",
    "        print(\"loss per valid token:\", float(loss.item()) / num_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_sum =   # whatever internal return\n",
    "print(\"crf -log_likelihood_sum:\", float(-log_likelihood_sum.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff72159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.AdamW(student_bilstm.parameters(), lr=2e-5)\n",
    "\n",
    "# trainer = KDTrainer(\n",
    "#     teacher_model=None,\n",
    "#     student_model=student_bilstm,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     optimizer=optimizer,\n",
    "#     alpha=0,\n",
    "#     beta=1,\n",
    "#     temperature=2.0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae8d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = trainer.train(num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535dfe1a",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "190381f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "================================================================================\n",
      "BASELINE TRAINING: 48 EXPERIMENTS\n",
      "================================================================================\n",
      "Device: cuda\n",
      "Epochs: 10\n",
      "Batch Size: 16\n",
      "Max Length: 128\n",
      "Running experiments 1 to 3\n",
      "================================================================================\n",
      "\n",
      "Loading label information...\n",
      "Number of labels: 35\n",
      "\n",
      "Total experiments to run: 3\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Experiment 1/48: distilbert_processed_2e-5_crf\n",
      "================================================================================\n",
      "Model: distilbert\n",
      "Dataset: processed\n",
      "Learning Rate: 2e-5\n",
      "CRF: True\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "Instantiating model: DistilBERTStudent...\n",
      "\n",
      "✗ Experiment 1 FAILED!\n",
      "Error: name 'DistilBERTStudent' is not defined\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Experiment 2/48: distilbert_processed_2e-5_nocrf\n",
      "================================================================================\n",
      "Model: distilbert\n",
      "Dataset: processed\n",
      "Learning Rate: 2e-5\n",
      "CRF: False\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "Instantiating model: DistilBERTStudent...\n",
      "\n",
      "✗ Experiment 2 FAILED!\n",
      "Error: name 'DistilBERTStudent' is not defined\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Experiment 3/48: distilbert_processed_5e-5_crf\n",
      "================================================================================\n",
      "Model: distilbert\n",
      "Dataset: processed\n",
      "Learning Rate: 5e-5\n",
      "CRF: True\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "Instantiating model: DistilBERTStudent...\n",
      "\n",
      "✗ Experiment 3 FAILED!\n",
      "Error: name 'DistilBERTStudent' is not defined\n",
      "\n",
      "\n",
      "✓ Summary saved to: results\\baseline\\summary.json\n",
      "\n",
      "================================================================================\n",
      "ALL EXPERIMENTS COMPLETED\n",
      "================================================================================\n",
      "Successful: 0\n",
      "Failed: 3\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comprehensive Baseline Training Script for NER Models\n",
    "Trains 4 models × 2 datasets × 3 learning rates × 2 CRF settings = 48 experiments\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Import your existing modules (assumed to be available)\n",
    "# from your_module import (\n",
    "#     NERDataset, create_dataloaders, load_label_info,\n",
    "#     QueryNERTeacher, DistilBERTStudent, TinyBertStudent, BiLSTMStudent,\n",
    "#     KDTrainer\n",
    "# )\n",
    "\n",
    "\n",
    "def create_experiment_config():\n",
    "    \"\"\"Generate all 48 experiment configurations\"\"\"\n",
    "    \n",
    "    # Configuration space\n",
    "    models = [\n",
    "        # (\"teacher\", \"QueryNERTeacher\", \"bltlab/queryner-augmented-data-bert-base-uncased\"),\n",
    "        (\"distilbert\", \"DistilBERTStudent\", \"distilbert-base-uncased\"),\n",
    "        (\"tinybert\", \"TinyBertStudent\", \"huawei-noah/TinyBERT_General_4L_312D\"),\n",
    "        (\"bilstm\", \"BiLSTMStudent\", \"bert-base-uncased\")\n",
    "    ]\n",
    "    \n",
    "    datasets = [\n",
    "        (\"processed\", {\n",
    "            \"train\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\train.json\",\n",
    "            \"val\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\validation.json\",\n",
    "            \"test\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\test.json\"\n",
    "        }),\n",
    "        (\"raw\", {\n",
    "            \"train\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\raw\\train.json\",\n",
    "            \"val\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\raw\\validation.json\",\n",
    "            \"test\": r\"D:\\Dafa\\Project\\queryner-kd\\data\\raw\\test.json\"\n",
    "        })\n",
    "    ]\n",
    "    \n",
    "    learning_rates = [\n",
    "        (2e-5, \"2e-5\"),   # Conservative, stable\n",
    "        (5e-5, \"5e-5\"),   # Balanced speed/stability\n",
    "        (1e-4, \"1e-4\")    # Faster convergence\n",
    "    ]\n",
    "    \n",
    "    crf_settings = [\n",
    "        (True, \"crf\"),\n",
    "        (False, \"nocrf\")\n",
    "    ]\n",
    "    \n",
    "    # Generate all combinations\n",
    "    experiments = []\n",
    "    exp_id = 1\n",
    "    \n",
    "    for model_name, model_class, model_path in models:\n",
    "        for data_name, data_paths in datasets:\n",
    "            for lr_value, lr_name in learning_rates:\n",
    "                for use_crf, crf_name in crf_settings:\n",
    "                    exp = {\n",
    "                        \"id\": exp_id,\n",
    "                        \"model_name\": model_name,\n",
    "                        \"model_class\": model_class,\n",
    "                        \"model_path\": model_path,\n",
    "                        \"data_name\": data_name,\n",
    "                        \"data_paths\": data_paths,\n",
    "                        \"learning_rate\": lr_value,\n",
    "                        \"lr_name\": lr_name,\n",
    "                        \"use_crf\": use_crf,\n",
    "                        \"crf_name\": crf_name,\n",
    "                        \"exp_name\": f\"{model_name}_{data_name}_{lr_name}_{crf_name}\"\n",
    "                    }\n",
    "                    experiments.append(exp)\n",
    "                    exp_id += 1\n",
    "    \n",
    "    return experiments\n",
    "\n",
    "\n",
    "def instantiate_model(model_class, model_path, label_info, use_crf, device):\n",
    "    \"\"\"Instantiate the correct model based on class name\"\"\"\n",
    "    \n",
    "    if model_class == \"QueryNERTeacher\":\n",
    "        model = QueryNERTeacher(\n",
    "            model_name=model_path,\n",
    "            label_info=label_info,\n",
    "            use_crf=use_crf\n",
    "        )\n",
    "    elif model_class == \"DistilBERTStudent\":\n",
    "        model = DistilBERTStudent(\n",
    "            model_name=model_path,\n",
    "            label_info=label_info,\n",
    "            use_crf=use_crf\n",
    "        )\n",
    "    elif model_class == \"TinyBertStudent\":\n",
    "        model = TinyBertStudent(\n",
    "            model_name=model_path,\n",
    "            label_info=label_info,\n",
    "            use_crf=use_crf\n",
    "        )\n",
    "    elif model_class == \"BiLSTMStudent\":\n",
    "        model = BiLSTMStudent(\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            use_crf=use_crf,\n",
    "            model_name_for_vocab=model_path,\n",
    "            label_info=label_info\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model class: {model_class}\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def train_single_experiment(exp, label_info, device, num_epochs=10, batch_size=16, max_length=128):\n",
    "    \"\"\"Train a single experiment configuration\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Experiment {exp['id']}/48: {exp['exp_name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Model: {exp['model_name']}\")\n",
    "    print(f\"Dataset: {exp['data_name']}\")\n",
    "    print(f\"Learning Rate: {exp['lr_name']}\")\n",
    "    print(f\"CRF: {exp['use_crf']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Loading data...\")\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        train_path=exp['data_paths']['train'],\n",
    "        val_path=exp['data_paths']['val'],\n",
    "        test_path=exp['data_paths']['test'],\n",
    "        model_name=\"bert-base-uncased\",  # tokenizer\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    # Instantiate model\n",
    "    print(f\"Instantiating model: {exp['model_class']}...\")\n",
    "    model = instantiate_model(\n",
    "        model_class=exp['model_class'],\n",
    "        model_path=exp['model_path'],\n",
    "        label_info=label_info,\n",
    "        use_crf=exp['use_crf'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=exp['learning_rate'])\n",
    "    \n",
    "    # Create trainer (using KD trainer with alpha=0, beta=1 for baseline)\n",
    "    trainer = KDTrainer(\n",
    "        teacher_model=None,  # No teacher for baseline\n",
    "        student_model=model,\n",
    "        train_loader=train_loader,\n",
    "        scheduler=scheduler,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        alpha=0.0,  # No KD loss\n",
    "        beta=1.0,   # Only student loss\n",
    "        temperature=2.0  # Not used when alpha=0\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(f\"Training for {num_epochs} epochs...\")\n",
    "    history = trainer.train(num_epochs=num_epochs)\n",
    "    \n",
    "    # Save results\n",
    "    save_experiment_results(exp, history)\n",
    "    \n",
    "    # Clear memory\n",
    "    del model, trainer, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def save_experiment_results(exp, history):\n",
    "    \"\"\"Save experiment results in organized structure\"\"\"\n",
    "    \n",
    "    # Create directory structure\n",
    "    base_dir = Path(\"results/baseline\")\n",
    "    json_dir = base_dir / \"json\"\n",
    "    img_dir = base_dir / \"img\"\n",
    "    \n",
    "    json_dir.mkdir(parents=True, exist_ok=True)\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save history as JSON\n",
    "    json_path = json_dir / f\"{exp['exp_name']}.json\"\n",
    "    \n",
    "    result_data = {\n",
    "        \"experiment\": exp,\n",
    "        \"history\": history,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(result_data, f, indent=4)\n",
    "    \n",
    "    print(f\"✓ Results saved to: {json_path}\")\n",
    "\n",
    "\n",
    "def run_all_baselines(\n",
    "    device=\"cuda\",\n",
    "    num_epochs=10,\n",
    "    batch_size=16,\n",
    "    max_length=128,\n",
    "    start_from=1,\n",
    "    end_at=48\n",
    "):\n",
    "    \"\"\"Run all 48 baseline experiments\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BASELINE TRAINING: 48 EXPERIMENTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Epochs: {num_epochs}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Max Length: {max_length}\")\n",
    "    print(f\"Running experiments {start_from} to {end_at}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load label info (use teacher model config)\n",
    "    print(\"Loading label information...\")\n",
    "    label_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")\n",
    "    print(f\"Number of labels: {label_info['num_labels']}\")\n",
    "    \n",
    "    # Generate all experiment configs\n",
    "    experiments = create_experiment_config()\n",
    "    \n",
    "    # Filter experiments based on start_from and end_at\n",
    "    experiments = [exp for exp in experiments if start_from <= exp['id'] <= end_at]\n",
    "    \n",
    "    print(f\"\\nTotal experiments to run: {len(experiments)}\\n\")\n",
    "    \n",
    "    # Track results\n",
    "    all_results = []\n",
    "    failed_experiments = []\n",
    "    \n",
    "    # Run each experiment\n",
    "    for i, exp in enumerate(experiments, 1):\n",
    "        try:\n",
    "            history = train_single_experiment(\n",
    "                exp=exp,\n",
    "                label_info=label_info,\n",
    "                device=device,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            # Store summary\n",
    "            final_metrics = {\n",
    "                \"exp_name\": exp['exp_name'],\n",
    "                \"val_f1\": history['val_f1'][-1],\n",
    "                \"val_precision\": history['val_precision'][-1],\n",
    "                \"val_recall\": history['val_recall'][-1],\n",
    "                \"best_val_f1\": max(history['val_f1'])\n",
    "            }\n",
    "            all_results.append(final_metrics)\n",
    "            \n",
    "            print(f\"\\n✓ Experiment {exp['id']} completed successfully!\")\n",
    "            print(f\"Final Val F1: {final_metrics['val_f1']:.4f}\")\n",
    "            print(f\"Best Val F1: {final_metrics['best_val_f1']:.4f}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ Experiment {exp['id']} FAILED!\")\n",
    "            print(f\"Error: {str(e)}\\n\")\n",
    "            failed_experiments.append({\n",
    "                \"exp_id\": exp['id'],\n",
    "                \"exp_name\": exp['exp_name'],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    # Save summary\n",
    "    save_summary(all_results, failed_experiments)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL EXPERIMENTS COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Successful: {len(all_results)}\")\n",
    "    print(f\"Failed: {len(failed_experiments)}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "def save_summary(all_results, failed_experiments):\n",
    "    \"\"\"Save summary of all experiments\"\"\"\n",
    "    \n",
    "    summary_dir = Path(\"results/baseline\")\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save results summary\n",
    "    summary_path = summary_dir / \"summary.json\"\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"successful_experiments\": all_results,\n",
    "            \"failed_experiments\": failed_experiments,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n✓ Summary saved to: {summary_path}\")\n",
    "    \n",
    "    # Print top performing models\n",
    "    if all_results:\n",
    "        print(\"\\nTop 5 Models by Best Val F1:\")\n",
    "        sorted_results = sorted(all_results, key=lambda x: x['best_val_f1'], reverse=True)\n",
    "        for i, result in enumerate(sorted_results[:5], 1):\n",
    "            print(f\"{i}. {result['exp_name']}: F1={result['best_val_f1']:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Check device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Run all baselines\n",
    "    # You can also run in batches:\n",
    "    # run_all_baselines(device=device, start_from=1, end_at=12)  # First 12\n",
    "    # run_all_baselines(device=device, start_from=13, end_at=24)  # Next 12\n",
    "    # run_all_baselines(device=device, start_from=25, end_at=36)  # Next 12\n",
    "    # run_all_baselines(device=device, start_from=37, end_at=48)  # Last 12\n",
    "    \n",
    "    run_all_baselines(\n",
    "        device=device,\n",
    "        num_epochs=10,\n",
    "        batch_size=16,\n",
    "        max_length=128,\n",
    "        start_from=1,\n",
    "        end_at=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c336c5",
   "metadata": {},
   "source": [
    "# Evaluate Teacher Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fdad443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model (should be in eval mode)\n",
    "        test_loader: Test DataLoader\n",
    "        device: Device to use\n",
    "        \n",
    "    Returns:\n",
    "        test_loss, test_kd, test_stu, test_precision, test_recall, test_f1\n",
    "    \"\"\"\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    tp_acc, pred_acc, actual_acc = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            batch_size, seq_len = input_ids.shape\n",
    "            \n",
    "            # Get model outputs\n",
    "            output = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            # Get loss\n",
    "            loss = output.get(\"loss\", torch.tensor(0.0, device=device))\n",
    "            total_loss += float(loss.item())\n",
    "            \n",
    "            # Get predictions\n",
    "            if \"pred\" in output:\n",
    "                pred = output[\"pred\"]\n",
    "                if isinstance(pred, torch.Tensor):\n",
    "                    pred_tensor = pred.to(device)\n",
    "                else:\n",
    "                    # Handle CRF list output\n",
    "                    pred_tensor = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n",
    "                    for i, p in enumerate(pred):\n",
    "                        if isinstance(p, torch.Tensor):\n",
    "                            p = p.tolist()\n",
    "                        L = len(p)\n",
    "                        if L > 0:\n",
    "                            pred_tensor[i, :L] = torch.tensor(p, dtype=torch.long, device=device)\n",
    "            else:\n",
    "                pred_tensor = output[\"logits\"].argmax(dim=-1)\n",
    "            \n",
    "            # Compute metrics\n",
    "            mask = attention_mask.bool()\n",
    "            valid = mask & (labels != -100)\n",
    "            \n",
    "            if valid.sum().item() > 0:\n",
    "                preds_flat = pred_tensor[valid].view(-1)\n",
    "                labels_flat = labels[valid].view(-1)\n",
    "                \n",
    "                # Compute TP, predicted, actual counts\n",
    "                tp = int((preds_flat == labels_flat).sum().item())\n",
    "                pred_count = int(preds_flat.numel())\n",
    "                actual_count = int(labels_flat.numel())\n",
    "                \n",
    "                tp_acc += tp\n",
    "                pred_acc += pred_count\n",
    "                actual_acc += actual_count\n",
    "    \n",
    "    # Compute averages\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    # Compute final metrics\n",
    "    precision = tp_acc / pred_acc if pred_acc > 0 else 0.0\n",
    "    recall = tp_acc / actual_acc if actual_acc > 0 else 0.0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    \n",
    "    return avg_loss, 0.0, avg_loss, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3330a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "teacher = AutoModelForTokenClassification.from_pretrained(\"bltlab/queryner-augmented-data-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06060d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853cf7678a494254b13527d2e4e2b133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "teacher.to(\"cuda\")\n",
    "test_loss, test_kd, test_stu, test_precision, test_recall, test_f1 = evaluate_on_test(teacher, test_loader, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "125d4b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 3.3270\n",
      "Test Precision: 0.6327\n",
      "Test Recall: 0.6327\n",
      "Test F1: 0.6327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfaa56",
   "metadata": {},
   "source": [
    "Raw\n",
    "- Test Loss: 3.3919\n",
    "- Test Precision: 0.6219\n",
    "- Test Recall: 0.6219\n",
    "- Test F1: 0.6219\n",
    "\n",
    "\n",
    "Processed\n",
    "- Test Loss: 3.3270\n",
    "- Test Precision: 0.6327\n",
    "- Test Recall: 0.6327\n",
    "- Test F1: 0.6327"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16277c",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "499a445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at bltlab/queryner-augmented-data-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# recreate model architecture exactly as during training\u001b[39;00m\n\u001b[0;32m      4\u001b[0m teacher \u001b[38;5;241m=\u001b[39m QueryNERTeacher(\n\u001b[0;32m      5\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbltlab/queryner-augmented-data-bert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     label_info\u001b[38;5;241m=\u001b[39mlabel_info,\n\u001b[0;32m      7\u001b[0m     use_crf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# or False depending how you trained\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[43mteacher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# load the state dict\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDafa\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqueryner-kd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mteacher_processed_5e-5_crf_best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1154\u001b[0m             device,\n\u001b[0;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1156\u001b[0m             non_blocking,\n\u001b[0;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1158\u001b[0m         )\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# recreate model architecture exactly as during training\n",
    "teacher = QueryNERTeacher(\n",
    "    model_name=\"bltlab/queryner-augmented-data-bert-base-uncased\",\n",
    "    label_info=label_info,\n",
    "    use_crf=True  # or False depending how you trained\n",
    ")\n",
    "teacher.to(device)\n",
    "\n",
    "# load the state dict\n",
    "ckpt_path = r\"D:\\Dafa\\Project\\queryner-kd\\teacher_processed_5e-5_crf_best.pt\"\n",
    "state = torch.load(ckpt_path, map_location=device)  # state is likely a dict of tensors\n",
    "\n",
    "# if you saved state_dict directly:\n",
    "if all(isinstance(v, torch.Tensor) for v in state.values()):\n",
    "    # probably you loaded state_dict directly\n",
    "    teacher.load_state_dict(state)\n",
    "else:\n",
    "    # fallback: if the checkpoint contains keys like 'model_state_dict'\n",
    "    if \"model_state_dict\" in state:\n",
    "        teacher.load_state_dict(state[\"model_state_dict\"])\n",
    "    elif \"state_dict\" in state:\n",
    "        teacher.load_state_dict(state[\"state_dict\"])\n",
    "    else:\n",
    "        # try to find the sub-dict that looks like state_dict\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, dict) and any(isinstance(t, torch.Tensor) for t in v.values()):\n",
    "                teacher.load_state_dict(v)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1bbc22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4338837194814b258f405fb104515137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m teacher\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m test_loss, test_kd, test_stu, test_precision, test_recall, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mevaluate_on_test\u001b[1;34m(model, test_loader, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m batch_size, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get model outputs\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get loss\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 23\u001b[0m, in \u001b[0;36mQueryNERTeacher.forward\u001b[1;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_crf:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1107\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[0;32m   1101\u001b[0m             attention_mask,\n\u001b[0;32m   1102\u001b[0m             input_shape,\n\u001b[0;32m   1103\u001b[0m             embedding_output,\n\u001b[0;32m   1104\u001b[0m             past_key_values_length,\n\u001b[0;32m   1105\u001b[0m         )\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1107\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:449\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    442\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    443\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing()\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy)\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mis_compiling())\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "teacher.to(\"cuda\")\n",
    "test_loss, test_kd, test_stu, test_precision, test_recall, test_f1 = evaluate_on_test(teacher, test_loader, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97c3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
