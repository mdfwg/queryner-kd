{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da811d97",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578e3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20489828",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3b264f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDafa\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqueryner-kd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     raw \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(raw))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m raw[:\u001b[38;5;241m2\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\train.json\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)[\"examples\"]\n",
    "\n",
    "print(len(raw))\n",
    "for item in raw[:2]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72521f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teeth', 'whitening', 'sensitive', 'teeth']\n",
      "[9, 10, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "tokens = raw[0][\"tokens\"]\n",
    "ner_tags = raw[0][\"ner_tags\"]\n",
    "print(tokens)\n",
    "print(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23907683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a29ffae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4091, 2317, 5582, 7591, 4091,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "670961cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 1, 2, 3, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "word_ids = encodings.word_ids(batch_index=0)\n",
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a27736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 4091, 2317, 5582, 7591, 4091,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50ff6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 9, 10, -100, 17, 18, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "aligned_labels = []\n",
    "previous_word_idx = None\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None:\n",
    "        aligned_labels.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        aligned_labels.append(ner_tags[word_idx])\n",
    "    else:\n",
    "        aligned_labels.append(-100)\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "print(aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cc6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 101, 4091, 2317, 5582, 7591, 4091,  102,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([-100,    9,   10, -100,   17,   18, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])}\n"
     ]
    }
   ],
   "source": [
    "item = {\n",
    "    \"input_ids\": encodings[\"input_ids\"].squeeze(0),\n",
    "    \"attention_mask\": encodings[\"attention_mask\"].squeeze(0),\n",
    "    \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n",
    "}\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f84955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, label_pad_id=-100, max_length=128):\n",
    "        ## khusus untuk data json\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw = json.load(f)[\"examples\"]\n",
    "        self.data = raw\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_pad_id = label_pad_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx][\"tokens\"]\n",
    "        ner_tags = self.data[idx][\"ner_tags\"]\n",
    "\n",
    "        # buat encoding untuk tokens \n",
    "        encoding = self.tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # align labels dengan tokens yang sudah diencoding (jadi kepotong2 sesuai tokenization)\n",
    "        word_ids = encoding.word_ids(batch_index=0)\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff168235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_info(model_name):\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    id2label = config.id2label\n",
    "    label2id = config.label2id\n",
    "    num_labels = config.num_labels\n",
    "\n",
    "    label_info = {\n",
    "        \"id2label\": id2label,\n",
    "        \"label2id\": label2id,\n",
    "        \"num_labels\": num_labels\n",
    "    }\n",
    "\n",
    "    return label_info\n",
    "\n",
    "def create_dataloaders(\n",
    "        train_path, val_path, test_path,\n",
    "        model_name,\n",
    "        batch_size=16,\n",
    "        max_length=128\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_dataset = NERDataset(train_path, tokenizer, max_length=max_length)\n",
    "    val_dataset = NERDataset(val_path, tokenizer, max_length=max_length)\n",
    "    test_dataset = NERDataset(test_path, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a2e0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NERDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNERDataset\u001b[49m(\n\u001b[0;32m      2\u001b[0m     data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDafa\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqueryner-kd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m train_dataset\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NERDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = NERDataset(\n",
    "    data_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\train.json\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce727dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x20d240cf500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83493b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  5519, 28712,  ...,     0,     0,     0],\n",
       "         [  101,  1017,  3204,  ...,     0,     0,     0],\n",
       "         [  101,  2148,  7363,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  8731,  1004,  ...,     0,     0,     0],\n",
       "         [  101,  2304,  3898,  ...,     0,     0,     0],\n",
       "         [  101, 24501, 19960,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[-100,    1,    1,  ..., -100, -100, -100],\n",
       "         [-100,   13,   14,  ..., -100, -100, -100],\n",
       "         [-100,    7, -100,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100,   11,   12,  ..., -100, -100, -100],\n",
       "         [-100,    3,    9,  ..., -100, -100, -100],\n",
       "         [-100,   11,   12,  ..., -100, -100, -100]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ddc8f6",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e8ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af932ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, label_pad_id=-100, max_length=128):\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw = json.load(f)[\"examples\"]\n",
    "        self.data = raw\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_pad_id = label_pad_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx][\"tokens\"]\n",
    "        ner_tags = self.data[idx][\"ner_tags\"]\n",
    "\n",
    "        # buat encoding untuk tokens \n",
    "        encoding = self.tokenizer(\n",
    "            tokens,\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # align labels dengan tokens yang sudah diencoding (jadi kepotong2 sesuai tokenization)\n",
    "        word_ids = encoding.word_ids(batch_index=0)\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(ner_tags[word_idx])\n",
    "            else:\n",
    "                aligned_labels.append(self.label_pad_id)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db94990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_info(model_name):\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    id2label = config.id2label\n",
    "    label2id = config.label2id\n",
    "    num_labels = config.num_labels\n",
    "\n",
    "    label_info = {\n",
    "        \"id2label\": id2label,\n",
    "        \"label2id\": label2id,\n",
    "        \"num_labels\": num_labels\n",
    "    }\n",
    "\n",
    "    return label_info\n",
    "\n",
    "def create_dataloaders(\n",
    "        train_path, val_path, test_path,\n",
    "        model_name,\n",
    "        batch_size=32,\n",
    "        max_length=128\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_dataset = NERDataset(train_path, tokenizer, max_length=max_length)\n",
    "    val_dataset = NERDataset(val_path, tokenizer, max_length=max_length)\n",
    "    test_dataset = NERDataset(test_path, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f43c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\train.json\",\n",
    "    val_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\validation.json\",\n",
    "    test_path=r\"D:\\Dafa\\Project\\queryner-kd\\data\\processed\\test.json\",\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    batch_size=16,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "label_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9cf707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10434,  8129,  ...,     0,     0,     0],\n",
       "         [  101,  8740, 14839,  ...,     0,     0,     0],\n",
       "         [  101,  2273,  5188,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  9587,  3334,  ...,     0,     0,     0],\n",
       "         [  101,  2822, 18059,  ...,     0,     0,     0],\n",
       "         [  101,  4268, 11220,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[-100,    7,   11,  ..., -100, -100, -100],\n",
       "         [-100,   11, -100,  ..., -100, -100, -100],\n",
       "         [-100,   13,   17,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100,   17, -100,  ..., -100, -100, -100],\n",
       "         [-100,   21,   25,  ..., -100, -100, -100],\n",
       "         [-100,   13,    9,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a14afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id2label', 'label2id', 'num_labels'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2775909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers import AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32576556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseNERModel\n",
    "label_info = label_info\n",
    "use_crf = False\n",
    "\n",
    "# QueryNER\n",
    "model_name = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=label_info[\"num_labels\"],\n",
    "    id2label=label_info[\"id2label\"],\n",
    "    label2id=label_info[\"label2id\"]\n",
    ")\n",
    "\n",
    "bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "dropout = nn.Dropout(0.1)\n",
    "classifier = nn.Linear(bert.config.hidden_size, bert.config.num_labels)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632ca302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "outputs = bert(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "outputs.last_hidden_state.shape  # (batch_size, seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c86719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output = dropout(outputs.last_hidden_state)\n",
    "sequence_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c72e0",
   "metadata": {},
   "source": [
    "#### Use CRF False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d0f372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 35])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = classifier(sequence_output)  # (batch_size, seq_len, num_labels)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f8f5835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5731, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(\n",
    "    logits.view(-1, label_info[\"num_labels\"]),\n",
    "    batch[\"labels\"].view(-1)\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5662fed",
   "metadata": {},
   "source": [
    "#### Use CRF True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f21e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n",
    "# result = self.crf_output(sequence_output, labels=labels, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07e92bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "# input nya sequence_output, labels, mask\n",
    "fc = nn.Linear(bert.config.hidden_size, bert.config.num_labels)\n",
    "crf = CRF(label_info[\"num_labels\"], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00fb7821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 35])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions = fc(sequence_output)  # (batch_size, seq_len, num_labels)\n",
    "emissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26de6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc2bf697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    7,   11,  ..., -100, -100, -100],\n",
       "        [-100,   11, -100,  ..., -100, -100, -100],\n",
       "        [-100,   13,   17,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100,   17, -100,  ..., -100, -100, -100],\n",
       "        [-100,   21,   25,  ..., -100, -100, -100],\n",
       "        [-100,   13,    9,  ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63ac6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = batch[\"attention_mask\"]\n",
    "mask = mask.bool()\n",
    "mask[:, 0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06bb0e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  7, 11,  ...,  0,  0,  0],\n",
       "        [ 0, 11,  0,  ...,  0,  0,  0],\n",
       "        [ 0, 13, 17,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0, 17,  0,  ...,  0,  0,  0],\n",
       "        [ 0, 21, 25,  ...,  0,  0,  0],\n",
       "        [ 0, 13,  9,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_crf = batch[\"labels\"]\n",
    "labels_crf[batch[\"labels\"] == -100] = 0\n",
    "labels_crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "763fdb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5964, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likehood = crf(emissions, batch[\"labels\"], mask=batch[\"attention_mask\"].bool(), reduction='token_mean')\n",
    "loss = -log_likehood\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fab67c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.87321063394683"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from train_loader, please get the average number of tokens per batch\n",
    "\n",
    "total_tokens = 0\n",
    "for batch in train_loader:\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    token_counts = attention_mask.sum().item()\n",
    "    total_tokens += token_counts\n",
    "\n",
    "total_tokens / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95d4084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 30, 11, 30, 2, 24],\n",
       " [11, 30, 2, 11, 5, 24],\n",
       " [21, 23, 14, 30, 14, 3],\n",
       " [11, 2, 19, 24],\n",
       " [11, 14, 21, 14, 30, 24],\n",
       " [23, 11, 19, 23, 23, 23, 24],\n",
       " [30, 20, 30, 23, 23, 33, 20, 14, 24],\n",
       " [11, 8, 19, 24],\n",
       " [23, 34, 23, 1, 1, 24],\n",
       " [11, 33, 19, 24],\n",
       " [30, 29, 30, 14, 30, 23, 21, 23, 31, 31, 19, 23, 24],\n",
       " [8, 19, 19, 24],\n",
       " [21, 18, 19, 13, 19, 24],\n",
       " [11, 29, 19, 19, 19, 19, 24],\n",
       " [22, 21, 33, 18, 1, 23, 24],\n",
       " [11, 33, 20, 23, 24]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = crf.decode(emissions, mask=batch[\"attention_mask\"].bool())\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9982c",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers import AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFOutputLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_labels):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, num_labels)\n",
    "        self.crf = CRF(num_tags=num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, outputs, labels=None, mask=None):\n",
    "        emissions = self.fc(outputs)\n",
    "\n",
    "        if labels is not None:\n",
    "            log_likelihood = self.crf(emissions, tags=labels, mask=mask, reduction=\"mean\")\n",
    "            loss = -log_likelihood\n",
    "            return {\"logits\": emissions, \"loss\": loss}\n",
    "        else:\n",
    "            pred = self.crf.decode(emissions, mask=mask)\n",
    "            return {\"logits\": emissions, \"pred\": pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63263ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNERModel(nn.Module):\n",
    "    def __init__(self, num_labels, use_crf=False):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.use_crf = use_crf\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        raise NotImplementedError(\"Forward method must be implemented in subclass.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryNER(BaseNERModel):\n",
    "    def __init__(self, model_name, label_info, use_crf=False):\n",
    "        super().__init__(num_labels=label_info[\"num_labels\"], use_crf=use_crf)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            id2label=label_info[\"id2label\"],\n",
    "            label2id=label_info[\"label2id\"]\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.config.num_labels)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
    "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab335654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERT(BaseNERModel):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", label_info=None, use_crf=False):\n",
    "        self.use_crf = use_crf\n",
    "        self.num_labels = label_info[\"num_labels\"]\n",
    "        super().__init__(num_labels=self.num_labels, use_crf=self.use_crf)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=label_info[\"num_labels\"],\n",
    "            id2label=label_info[\"id2label\"],\n",
    "            label2id=label_info[\"label2id\"]\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        if self.use_crf:\n",
    "            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "\n",
    "        if self.use_crf:\n",
    "            mask = attention_mask.bool()\n",
    "            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n",
    "            return result\n",
    "        else:\n",
    "            logits = self.classifier(sequence_output)\n",
    "            if labels is not None:\n",
    "                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "                return {\"logits\": logits, \"loss\": loss}\n",
    "            else:\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                return {\"logits\": logits, \"pred\": pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f815857",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = QueryNER(\"bert-base-uncased\", label_info, use_crf=False)\n",
    "student = DistilBERT(label_info=label_info, use_crf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e552b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "labels = batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16545f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([16, 128])\n",
      "attention_mask shape: torch.Size([16, 128])\n",
      "labels shape: torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0aba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 9 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[212], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m t_result \u001b[38;5;241m=\u001b[39m \u001b[43mteacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "Cell \u001b[1;32mIn[188], line 34\u001b[0m, in \u001b[0;36mQueryNER.forward\u001b[1;34m(self, input_ids, attention_mask, labels)\u001b[0m\n",
      "\u001b[0;32m     32\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m---> 34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss}\n",
      "\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n",
      "\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n",
      "\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n",
      "\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 9 is out of bounds."
     ]
    }
   ],
   "source": [
    "t_result = teacher(input_ids=input_ids, attention_mask=attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0608bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[179], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m s_result \u001b[38;5;241m=\u001b[39m \u001b[43mstudent\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "Cell \u001b[1;32mIn[170], line 24\u001b[0m, in \u001b[0;36mDistilBERT.forward\u001b[1;34m(self, input_ids, attention_mask, labels)\u001b[0m\n",
      "\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     25\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n",
      "\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_crf:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:802\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n",
      "\u001b[0;32m    800\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n",
      "\u001b[1;32m--> 802\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n",
      "\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n",
      "\u001b[0;32m    805\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:125\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n",
      "\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n",
      "\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n",
      "\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 125\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[0;32m    127\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n",
      "\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n",
      "\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# isues similar to issue #5664\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gnn\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n",
      "\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n",
      "\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n",
      "\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n",
      "\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n",
      "\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n",
      "\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n",
      "\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "s_result = student(input_ids=input_ids, attention_mask=attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f0d22",
   "metadata": {},
   "source": [
    "## CRF Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b60eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 5\n",
    "model = CRF(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7358b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5])\n",
      "tensor([[[-0.9194, -0.4299, -2.3956,  0.7575,  0.5029],\n",
      "         [ 0.3142, -0.8432, -0.7544, -0.6260, -0.8528]],\n",
      "\n",
      "        [[-1.1581, -0.1062, -0.3376,  0.0401, -0.3961],\n",
      "         [ 1.1090, -1.3114, -0.1248, -0.4729,  0.4600]],\n",
      "\n",
      "        [[-0.5804,  0.7643,  0.8325, -0.6142, -1.6916],\n",
      "         [-0.8408, -0.5836,  0.6385, -1.1154,  1.0496]]])\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "batch_size = 2\n",
    "emissions = torch.randn(seq_length, batch_size, num_tags)\n",
    "print(emissions.shape)\n",
    "print(emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7036e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = torch.tensor([\n",
    "    [0, 1], [2, 4], [3, 1]], dtype=torch.long\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616d13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-12.1175, grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(emissions, tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
