{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13787301,"sourceType":"datasetVersion","datasetId":8768140},{"sourceId":656698,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":496371,"modelId":511779}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"!pip install torch transformers pytorch-crf tqdm pandas matplotlib seaborn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:39:12.257815Z","iopub.execute_input":"2025-11-27T07:39:12.258043Z","iopub.status.idle":"2025-11-27T07:40:26.076904Z","shell.execute_reply.started":"2025-11-27T07:39:12.258023Z","shell.execute_reply":"2025-11-27T07:40:26.076022Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting pytorch-crf\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nInstalling collected packages: pytorch-crf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-crf-0.7.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:26.077997Z","iopub.execute_input":"2025-11-27T07:40:26.078282Z","iopub.status.idle":"2025-11-27T07:40:35.478993Z","shell.execute_reply.started":"2025-11-27T07:40:26.078249Z","shell.execute_reply":"2025-11-27T07:40:35.478184Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class NERDataset(Dataset):\n    def __init__(self, data_path, tokenizer, label_pad_id=-100, max_length=128):\n        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n            raw = json.load(f)[\"examples\"]\n        self.data = raw\n        self.tokenizer = tokenizer\n        self.label_pad_id = label_pad_id\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        tokens = self.data[idx][\"tokens\"]\n        ner_tags = self.data[idx][\"ner_tags\"]\n \n        encoding = self.tokenizer(\n            tokens,\n            is_split_into_words=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n\n        word_ids = encoding.word_ids(batch_index=0)\n        aligned_labels = []\n        previous_word_idx = None\n        for word_idx in word_ids:\n            if word_idx is None:\n                aligned_labels.append(self.label_pad_id)\n            elif word_idx != previous_word_idx:\n                aligned_labels.append(ner_tags[word_idx])\n            else:\n                aligned_labels.append(self.label_pad_id)\n            previous_word_idx = word_idx\n        \n        item = {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"labels\": torch.tensor(aligned_labels, dtype=torch.long)\n        }\n\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.480944Z","iopub.execute_input":"2025-11-27T07:40:35.481300Z","iopub.status.idle":"2025-11-27T07:40:35.489571Z","shell.execute_reply.started":"2025-11-27T07:40:35.481282Z","shell.execute_reply":"2025-11-27T07:40:35.488542Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_label_info(model_name):\n    config = AutoConfig.from_pretrained(model_name)\n    id2label = config.id2label\n    label2id = config.label2id\n    num_labels = config.num_labels\n\n    label_info = {\n        \"id2label\": id2label,\n        \"label2id\": label2id,\n        \"num_labels\": num_labels\n    }\n\n    return label_info\n\ndef create_dataloaders(\n        train_path, val_path, test_path,\n        model_name,\n        batch_size=32,\n        max_length=128\n):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    train_dataset = NERDataset(train_path, tokenizer, max_length=max_length)\n    val_dataset = NERDataset(val_path, tokenizer, max_length=max_length)\n    test_dataset = NERDataset(test_path, tokenizer, max_length=max_length)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.490401Z","iopub.execute_input":"2025-11-27T07:40:35.490663Z","iopub.status.idle":"2025-11-27T07:40:35.509234Z","shell.execute_reply.started":"2025-11-27T07:40:35.490639Z","shell.execute_reply":"2025-11-27T07:40:35.508373Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom torchcrf import CRF\nfrom transformers import AutoModel, AutoConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.510131Z","iopub.execute_input":"2025-11-27T07:40:35.510602Z","iopub.status.idle":"2025-11-27T07:40:35.548239Z","shell.execute_reply.started":"2025-11-27T07:40:35.510575Z","shell.execute_reply":"2025-11-27T07:40:35.547515Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class CRFOutputLayer(nn.Module):\n    def __init__(self, hidden_dim, num_labels):\n        super().__init__()\n        self.fc = nn.Linear(hidden_dim, num_labels)\n        self.crf = CRF(num_tags=num_labels, batch_first=True)\n\n    def forward(self, outputs, labels=None, mask=None):\n        emissions = self.fc(outputs)\n\n        if labels is not None:\n            if mask is None:\n                mask = torch.ones_like(labels, dtype=torch.bool)\n            else:\n                mask = mask.bool()\n            \n            mask[:, 0] = True\n            \n            labels_crf = labels.clone()\n            labels_crf[labels == -100] = 0\n            \n            log_likelihood = self.crf(emissions, tags=labels_crf, mask=mask, reduction=\"token_mean\")\n            loss = -log_likelihood\n            return {\"logits\": emissions, \"loss\": loss}\n        else:\n            if mask is None:\n                mask = torch.ones(outputs.shape[:2], dtype=torch.bool, device=outputs.device)\n            pred = self.crf.decode(emissions, mask=mask.bool())\n            return {\"logits\": emissions, \"pred\": pred}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.549046Z","iopub.execute_input":"2025-11-27T07:40:35.549338Z","iopub.status.idle":"2025-11-27T07:40:35.555796Z","shell.execute_reply.started":"2025-11-27T07:40:35.549275Z","shell.execute_reply":"2025-11-27T07:40:35.555019Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class BaseNERModel(nn.Module):\n    def __init__(self, num_labels, use_crf=False):\n        super().__init__()\n        self.num_labels = num_labels\n        self.use_crf = use_crf\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        raise NotImplementedError(\"Forward method must be implemented in subclass.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.556611Z","iopub.execute_input":"2025-11-27T07:40:35.556890Z","iopub.status.idle":"2025-11-27T07:40:35.571984Z","shell.execute_reply.started":"2025-11-27T07:40:35.556861Z","shell.execute_reply":"2025-11-27T07:40:35.571217Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class QueryNERTeacher(BaseNERModel):\n    def __init__(self, model_name, label_info, use_crf=False):\n        super().__init__(num_labels=label_info[\"num_labels\"], use_crf=use_crf)\n\n        self.config = AutoConfig.from_pretrained(\n            model_name,\n            num_labels=label_info[\"num_labels\"],\n            id2label=label_info[\"id2label\"],\n            label2id=label_info[\"label2id\"]\n        )\n\n        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n        self.dropout = nn.Dropout(0.3)\n\n        if self.use_crf:\n            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.config.num_labels)\n        else:\n            self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = self.dropout(outputs.last_hidden_state)\n\n        if self.use_crf:\n            mask = attention_mask.bool()\n            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n            return result\n\n        else:\n            logits = self.classifier(sequence_output)\n            if labels is not None:\n                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n                return {\"logits\": logits, \"loss\": loss}\n            else:\n                pred = logits.argmax(dim=-1)\n                return {\"logits\": logits, \"pred\": pred}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.572871Z","iopub.execute_input":"2025-11-27T07:40:35.573150Z","iopub.status.idle":"2025-11-27T07:40:35.589599Z","shell.execute_reply.started":"2025-11-27T07:40:35.573124Z","shell.execute_reply":"2025-11-27T07:40:35.588771Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class DistilBERTStudent(BaseNERModel):\n    def __init__(self, model_name=\"distilbert-base-uncased\", label_info=None, use_crf=False):\n        self.use_crf = use_crf\n        self.num_labels = label_info[\"num_labels\"]\n        super().__init__(num_labels=self.num_labels, use_crf=self.use_crf)\n\n        self.config = AutoConfig.from_pretrained(\n            model_name,\n            num_labels=label_info[\"num_labels\"],\n            id2label=label_info[\"id2label\"],\n            label2id=label_info[\"label2id\"]\n        )\n\n        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n        self.dropout = nn.Dropout(0.3)\n\n        if self.use_crf:\n            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n        else:\n            self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = self.dropout(outputs.last_hidden_state)\n\n        if self.use_crf:\n            mask = attention_mask.bool()\n            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n            return result\n        else:\n            logits = self.classifier(sequence_output)\n            if labels is not None:\n                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n                return {\"logits\": logits, \"loss\": loss}\n            else:\n                pred = logits.argmax(dim=-1)\n                return {\"logits\": logits, \"pred\": pred}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.592305Z","iopub.execute_input":"2025-11-27T07:40:35.592555Z","iopub.status.idle":"2025-11-27T07:40:35.606894Z","shell.execute_reply.started":"2025-11-27T07:40:35.592538Z","shell.execute_reply":"2025-11-27T07:40:35.606074Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class TinyBertStudent(BaseNERModel):\n    def __init__(self, model_name=\"huawei-noah/TinyBERT_General_4L_312D\", label_info=None, use_crf=False):\n        self.use_crf = use_crf\n        self.num_labels = label_info[\"num_labels\"]\n        super().__init__(num_labels=self.num_labels, use_crf=self.use_crf)\n\n        self.config = AutoConfig.from_pretrained(\n            model_name,\n            num_labels=label_info[\"num_labels\"],\n            id2label=label_info[\"id2label\"],\n            label2id=label_info[\"label2id\"]\n        )\n\n        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n        self.dropout = nn.Dropout(0.3)\n\n        if self.use_crf:\n            self.crf_output = CRFOutputLayer(self.config.hidden_size, self.num_labels)\n        else:\n            self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n            self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = self.dropout(outputs.last_hidden_state)\n\n        if self.use_crf:\n            mask = attention_mask.bool()\n            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n            return result\n        else:\n            logits = self.classifier(sequence_output)\n            if labels is not None:\n                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n                return {\"logits\": logits, \"loss\": loss}\n            else:\n                pred = logits.argmax(dim=-1)\n                return {\"logits\": logits, \"pred\": pred}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.607967Z","iopub.execute_input":"2025-11-27T07:40:35.608260Z","iopub.status.idle":"2025-11-27T07:40:35.626069Z","shell.execute_reply.started":"2025-11-27T07:40:35.608237Z","shell.execute_reply":"2025-11-27T07:40:35.625211Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class BiLSTMStudent(BaseNERModel):\n    def __init__(\n            self,  \n            use_crf=False,\n            model_name_for_vocab = 'bert-base-uncased',\n            emb_dim = 300,\n            lstm_hidden = 300,\n            label_info = None,\n            pad_token_id = 0,\n            teacher_model = None\n        ):\n        self.use_crf = use_crf\n        self.num_labels = label_info[\"num_labels\"]\n        super().__init__(self.num_labels, use_crf)\n\n        config = AutoConfig.from_pretrained(model_name_for_vocab)\n        vocab_size = config.vocab_size\n        pad_token_id = config.pad_token_id\n\n        if teacher_model is not None:\n            self.embedding = teacher_model.bert.embeddings.word_embeddings\n            for p in self.embedding.parameters():\n                p.requires_grad = False\n            emb_dim_eff = self.embedding.embedding_dim\n        else:\n            emb_dim_eff = emb_dim\n            self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_token_id)\n        self.dropout = nn.Dropout(0.1)\n        self.lstm = nn.LSTM(\n            input_size=emb_dim_eff,\n            hidden_size=lstm_hidden,\n            num_layers=1,\n            batch_first=True,\n            bidirectional=True\n        )\n        self.classifier = nn.Linear(lstm_hidden * 2, self.num_labels)\n        self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n\n        if self.use_crf:\n            self.crf_output = CRFOutputLayer(hidden_dim=lstm_hidden * 2, num_labels=self.num_labels)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        emb = self.embedding(input_ids)\n        emb = self.dropout(emb)\n        outputs, _ = self.lstm(emb)\n        sequence_output = outputs\n\n        if self.use_crf:\n            mask = attention_mask.bool()\n            result = self.crf_output(sequence_output, labels=labels, mask=mask)\n            return result\n        else:\n            logits = self.classifier(sequence_output)\n            if labels is not None:\n                loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n                return {\"logits\": logits, \"loss\": loss}\n            else:\n                pred = logits.argmax(dim=-1)\n                return {\"logits\": logits, \"pred\": pred}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.626969Z","iopub.execute_input":"2025-11-27T07:40:35.627354Z","iopub.status.idle":"2025-11-27T07:40:35.642791Z","shell.execute_reply.started":"2025-11-27T07:40:35.627314Z","shell.execute_reply":"2025-11-27T07:40:35.642068Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Knowledge Distillation Scheme","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.643642Z","iopub.execute_input":"2025-11-27T07:40:35.643952Z","iopub.status.idle":"2025-11-27T07:40:35.658022Z","shell.execute_reply.started":"2025-11-27T07:40:35.643930Z","shell.execute_reply":"2025-11-27T07:40:35.657315Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def softmax_with_temperature(logits, temperature):\n    return F.softmax(logits / temperature, dim=-1)\n\ndef kl_divergence_loss(student_logits, teacher_logits, temperature):\n    p_teacher = F.log_softmax(teacher_logits / temperature, dim=-1)\n    p_student = F.softmax(student_logits / temperature, dim=-1)\n    loss = F.kl_div(p_teacher, p_student, reduction='batchmean')\n    loss = loss * (temperature ** 2)\n    return loss\n\ndef kl_divergence_loss_masked(student_logits, teacher_logits, temperature, mask=None, eps=1e-12):\n    T = float(temperature)\n\n    student_log_prob = F.log_softmax(student_logits / T, dim=-1)   # (B, L, C)\n    teacher_prob = F.softmax(teacher_logits / T, dim=-1)           # (B, L, C)\n\n    kl_elem = F.kl_div(student_log_prob, teacher_prob, reduction='none')  # (B, L, C)\n\n    kl_token = kl_elem.sum(dim=-1)  # (B, L)\n\n    if mask is not None:\n        mask = mask.bool()\n        valid_sum = mask.float().sum()\n        if valid_sum.item() == 0:\n            return torch.tensor(0.0, device=student_logits.device)\n        kl_sum = (kl_token * mask.float()).sum()\n        return (kl_sum / valid_sum) * (T * T)\n    else:\n        return kl_token.mean() * (T * T)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.658875Z","iopub.execute_input":"2025-11-27T07:40:35.659112Z","iopub.status.idle":"2025-11-27T07:40:35.674773Z","shell.execute_reply.started":"2025-11-27T07:40:35.659089Z","shell.execute_reply":"2025-11-27T07:40:35.673950Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\n\n\ndef kl_divergence_loss_masked(student_logits, teacher_logits, temperature, mask=None, eps=1e-12):\n    \"\"\"\n    Compute masked KL divergence loss for knowledge distillation.\n    \n    Args:\n        student_logits: (B, L, C) logits from student\n        teacher_logits: (B, L, C) logits from teacher\n        temperature: Temperature for softening distributions\n        mask: (B, L) attention mask (1 for valid tokens)\n        eps: Small constant for numerical stability\n    \n    Returns:\n        Scalar loss value\n    \"\"\"\n    T = float(temperature)\n\n    student_log_prob = F.log_softmax(student_logits / T, dim=-1)   # (B, L, C)\n    teacher_prob = F.softmax(teacher_logits / T, dim=-1)           # (B, L, C)\n\n    kl_elem = F.kl_div(student_log_prob, teacher_prob, reduction='none')  # (B, L, C)\n    kl_token = kl_elem.sum(dim=-1)  # (B, L)\n\n    if mask is not None:\n        mask = mask.bool()\n        valid_sum = mask.float().sum()\n        if valid_sum.item() == 0:\n            return torch.tensor(0.0, device=student_logits.device)\n        kl_sum = (kl_token * mask.float()).sum()\n        return (kl_sum / valid_sum) * (T * T)\n    else:\n        return kl_token.mean() * (T * T)\n\n\ndef _to_tensor_preds(preds, batch_size, seq_len, device):\n    \"\"\"\n    Convert CRF decode output (list[list[int]] or list of tensors) into a tensor\n    of shape (batch_size, seq_len) padded with 0s. Caller must mask invalid tokens.\n    \"\"\"\n    pred_tensor = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n    for i, p in enumerate(preds):\n        if isinstance(p, torch.Tensor):\n            p = p.tolist()\n        L = len(p)\n        if L > 0:\n            pred_tensor[i, :L] = torch.tensor(p, dtype=torch.long, device=device)\n    return pred_tensor\n\n\ndef _safe_get_pred_tensor(output, batch_size, seq_len, device):\n    \"\"\"\n    Return a (batch, seq_len) tensor of predictions from model output.\n    Handles:\n      - output[\"pred\"] is a tensor (batch, seq_len)\n      - output[\"pred\"] is a list of lists (per-seq predicted label ids)\n      - output has no \"pred\" (use logits.argmax)\n    \"\"\"\n    if \"pred\" in output:\n        pred = output[\"pred\"]\n        if isinstance(pred, torch.Tensor):\n            return pred.to(device)\n        else:\n            # assume list of lists\n            return _to_tensor_preds(pred, batch_size, seq_len, device)\n    elif \"logits\" in output:\n        return output[\"logits\"].argmax(dim=-1).to(device)\n    else:\n        raise ValueError(\"No 'pred' or 'logits' in model output to produce predictions.\")\n\n\ndef _accumulate_confusion_counts(preds_flat, labels_flat):\n    \"\"\"\n    Compute per-class TP, predicted_counts, actual_counts using vectors.\n    preds_flat and labels_flat are 1D torch.Long tensors on CPU or device.\n    Returns (tp_sum, pred_sum, actual_sum) and also total_tp, total_pred, total_actual per class sums.\n    \"\"\"\n    if preds_flat.numel() == 0:\n        return 0, 0, 0, None\n\n    max_label = int(max(int(preds_flat.max().item()), int(labels_flat.max().item())))\n    num_classes = max_label + 1\n\n    tp_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n    pred_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n    actual_per_class = torch.zeros(num_classes, dtype=torch.long, device=preds_flat.device)\n\n    for c in range(num_classes):\n        pred_mask = preds_flat == c\n        lab_mask = labels_flat == c\n        tp_per_class[c] = int((pred_mask & lab_mask).sum().item())\n        pred_per_class[c] = int(pred_mask.sum().item())\n        actual_per_class[c] = int(lab_mask.sum().item())\n\n    tp_sum = int(tp_per_class.sum().item())\n    pred_sum = int(pred_per_class.sum().item())\n    actual_sum = int(actual_per_class.sum().item())\n\n    return tp_sum, pred_sum, actual_sum, (tp_per_class.cpu().numpy(), pred_per_class.cpu().numpy(), actual_per_class.cpu().numpy())\n\n\ndef _batch_metrics(pred_tensor, label_tensor, attention_mask):\n    \"\"\"\n    pred_tensor: (B, L)\n    label_tensor: (B, L) with -100 for ignored positions\n    attention_mask: (B, L) with 1 for valid tokens\n    Returns TP, predicted_count, actual_count (ints)\n    \"\"\"\n    mask = attention_mask.bool()\n    # also ensure labels not equal to -100 in valid positions\n    valid = mask & (label_tensor != -100)\n    if valid.sum().item() == 0:\n        return 0, 0, 0\n\n    preds_flat = pred_tensor[valid].view(-1)\n    labels_flat = label_tensor[valid].view(-1)\n\n    tp_sum, pred_sum, actual_sum, _ = _accumulate_confusion_counts(preds_flat, labels_flat)\n    return tp_sum, pred_sum, actual_sum\n\n\ndef _final_metrics(tp_sum, pred_sum, actual_sum):\n    \"\"\"\n    Compute micro precision, recall, f1 from aggregated counts.\n    \"\"\"\n    precision = tp_sum / pred_sum if pred_sum > 0 else 0.0\n    recall = tp_sum / actual_sum if actual_sum > 0 else 0.0\n    if precision + recall > 0:\n        f1 = 2 * precision * recall / (precision + recall)\n    else:\n        f1 = 0.0\n    return precision, recall, f1\n\n\nclass KDTrainer:\n    \"\"\"\n    Trainer for both baseline (fine-tuning) and knowledge distillation.\n    \n    For baseline:\n        teacher_model=None, alpha=0, beta=1\n    \n    For KD:\n        teacher_model=<trained_model>, alpha=0.5, beta=0.5\n    \"\"\"\n    \n    def __init__(\n        self,\n        teacher_model,\n        student_model,\n        train_loader,\n        val_loader,\n        optimizer,\n        scheduler=None,\n        device=\"cuda\",\n        alpha=0.5,\n        beta=0.5,\n        temperature=2.0,\n        scheduler_type=\"plateau\"  # \"plateau\", \"cosine\", \"step\", or None\n    ):\n        \"\"\"\n        Args:\n            teacher_model: Teacher model (None for baseline)\n            student_model: Student model to train\n            train_loader: Training DataLoader\n            val_loader: Validation DataLoader\n            optimizer: Optimizer for student model\n            scheduler: Learning rate scheduler (optional)\n            device: Device to use\n            alpha: Weight for KD loss (0 for baseline)\n            beta: Weight for student loss (1 for baseline)\n            temperature: Temperature for KD\n            scheduler_type: Type of scheduler for proper step() call\n        \"\"\"\n        self.student = student_model.to(device)\n        self.teacher = None  # ← FIX: Initialize to None\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.scheduler_type = scheduler_type\n        self.device = device\n        self.alpha = alpha\n        self.beta = beta\n        self.T = temperature\n\n        # Setup teacher if provided\n        if teacher_model is not None:\n            self.teacher = teacher_model.to(device)\n            self.teacher.eval()  # Set to eval mode\n            for p in self.teacher.parameters():\n                p.requires_grad = False\n        \n        # Validate configuration\n        if self.alpha > 0 and self.teacher is None:\n            raise ValueError(\"alpha > 0 requires a teacher model!\")\n        \n        # Print training mode\n        mode = \"BASELINE\" if self.teacher is None else \"KNOWLEDGE DISTILLATION\"\n        print(f\"\\n{'='*60}\")\n        print(f\"Training Mode: {mode}\")\n        print(f\"Alpha (KD loss weight): {self.alpha}\")\n        print(f\"Beta (Student loss weight): {self.beta}\")\n        print(f\"Temperature: {self.T}\")\n        print(f\"{'='*60}\\n\")\n\n    def compute_losses(self, batch):\n        \"\"\"\n        Compute losses for one batch.\n        \n        Returns:\n            loss_total: Combined loss\n            loss_kd: KD loss (0 if no teacher)\n            loss_student: Student task loss\n            pred_tensor: Predictions for metrics\n            labels: Ground truth labels\n            attention_mask: Attention mask\n        \"\"\"\n        input_ids = batch[\"input_ids\"].to(self.device)\n        attention_mask = batch[\"attention_mask\"].to(self.device)\n        labels = batch[\"labels\"].to(self.device)\n\n        batch_size, seq_len = input_ids.shape\n\n        # Get teacher logits if needed\n        teacher_logits = None\n        if self.alpha > 0 and self.teacher is not None:\n            with torch.no_grad():\n                self.teacher.eval()\n                teacher_out = self.teacher(\n                    input_ids=input_ids, \n                    attention_mask=attention_mask\n                )\n                teacher_logits = teacher_out[\"logits\"]\n\n        # Get student outputs\n        student_out = self.student(\n            input_ids=input_ids, \n            attention_mask=attention_mask, \n            labels=labels\n        )\n        student_logits = student_out[\"logits\"]\n\n        # Compute KD loss if teacher provided\n        if teacher_logits is not None:\n            loss_kd = kl_divergence_loss_masked(\n                student_logits, \n                teacher_logits, \n                self.T, \n                mask=attention_mask\n            )\n        else:\n            loss_kd = torch.tensor(0.0, device=self.device)\n\n        # Get student task loss\n        loss_student = student_out.get(\"loss\", torch.tensor(0.0, device=self.device))\n\n        # Combined loss\n        loss_total = self.alpha * loss_kd + self.beta * loss_student\n\n        # Get predictions for metrics\n        pred_tensor = _safe_get_pred_tensor(student_out, batch_size, seq_len, self.device)\n\n        return loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask\n\n    def train_epoch(self):\n        \"\"\"Train for one epoch.\"\"\"\n        self.student.train()\n        total_loss, total_kd, total_stu = 0.0, 0.0, 0.0\n        tp_acc, pred_acc, actual_acc = 0, 0, 0\n\n        for batch in tqdm(self.train_loader, desc=\"Training\"):\n            self.optimizer.zero_grad()\n            \n            loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask = \\\n                self.compute_losses(batch)\n            \n            loss_total.backward()\n            self.optimizer.step()\n\n            total_loss += float(loss_total.item())\n            total_kd += float(loss_kd.item())\n            total_stu += float(loss_student.item()) if isinstance(loss_student, torch.Tensor) else float(loss_student)\n\n            tp, pred_count, actual_count = _batch_metrics(pred_tensor, labels, attention_mask)\n            tp_acc += tp\n            pred_acc += pred_count\n            actual_acc += actual_count\n\n        avg_loss = total_loss / len(self.train_loader)\n        avg_kd = total_kd / len(self.train_loader)\n        avg_stu = total_stu / len(self.train_loader)\n\n        # Update scheduler if provided\n        if self.scheduler:\n            if self.scheduler_type == \"plateau\":\n                self.scheduler.step(avg_loss)\n            else:\n                # For cosine, step, etc. that don't need metrics\n                self.scheduler.step()\n\n        precision, recall, f1 = _final_metrics(tp_acc, pred_acc, actual_acc)\n        return avg_loss, avg_kd, avg_stu, precision, recall, f1\n\n    def validate(self):\n        \"\"\"Validate on validation set.\"\"\"\n        self.student.eval()\n        total_loss, total_kd, total_stu = 0.0, 0.0, 0.0\n        tp_acc, pred_acc, actual_acc = 0, 0, 0\n\n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n                loss_total, loss_kd, loss_student, pred_tensor, labels, attention_mask = \\\n                    self.compute_losses(batch)\n                \n                total_loss += float(loss_total.item())\n                total_kd += float(loss_kd.item())\n                total_stu += float(loss_student.item()) if isinstance(loss_student, torch.Tensor) else float(loss_student)\n\n                tp, pred_count, actual_count = _batch_metrics(pred_tensor, labels, attention_mask)\n                tp_acc += tp\n                pred_acc += pred_count\n                actual_acc += actual_count\n\n        avg_loss = total_loss / len(self.val_loader)\n        avg_kd = total_kd / len(self.val_loader)\n        avg_stu = total_stu / len(self.val_loader)\n\n        precision, recall, f1 = _final_metrics(tp_acc, pred_acc, actual_acc)\n        return avg_loss, avg_kd, avg_stu, precision, recall, f1\n\n    def train(self, num_epochs):\n        \"\"\"\n        Train for multiple epochs.\n        \n        Args:\n            num_epochs: Number of epochs to train\n            \n        Returns:\n            history: Dictionary containing training history\n        \"\"\"\n        history = {\n            \"train_loss\": [], \"val_loss\": [],\n            \"train_kd\": [], \"val_kd\": [],\n            \"train_stu\": [], \"val_stu\": [],\n            \"train_precision\": [], \"train_recall\": [], \"train_f1\": [],\n            \"val_precision\": [], \"val_recall\": [], \"val_f1\": []\n        }\n\n        best_val_f1 = 0.0\n        \n        for epoch in range(1, num_epochs + 1):\n            print(f\"\\n{'='*60}\")\n            print(f\"EPOCH {epoch}/{num_epochs}\")\n            print(f\"{'='*60}\")\n            \n            train_loss, train_kd, train_stu, train_prec, train_rec, train_f1 = self.train_epoch()\n            val_loss, val_kd, val_stu, val_prec, val_rec, val_f1 = self.validate()\n\n            print(f\"\\nTrain Loss: {train_loss:.4f} (KD: {train_kd:.4f}, Student: {train_stu:.4f})\")\n            print(f\"Val Loss:   {val_loss:.4f} (KD: {val_kd:.4f}, Student: {val_stu:.4f})\")\n            print(f\"\\nTrain Metrics -> P: {train_prec:.4f}, R: {train_rec:.4f}, F1: {train_f1:.4f}\")\n            print(f\"Val Metrics   -> P: {val_prec:.4f}, R: {val_rec:.4f}, F1: {val_f1:.4f}\")\n            \n            # Track best validation F1\n            if val_f1 > best_val_f1:\n                best_val_f1 = val_f1\n                print(f\"✓ New best Val F1: {best_val_f1:.4f}\")\n\n            # Store history\n            history[\"train_loss\"].append(train_loss)\n            history[\"train_kd\"].append(train_kd)\n            history[\"train_stu\"].append(train_stu)\n            history[\"val_loss\"].append(val_loss)\n            history[\"val_kd\"].append(val_kd)\n            history[\"val_stu\"].append(val_stu)\n\n            history[\"train_precision\"].append(train_prec)\n            history[\"train_recall\"].append(train_rec)\n            history[\"train_f1\"].append(train_f1)\n            history[\"val_precision\"].append(val_prec)\n            history[\"val_recall\"].append(val_rec)\n            history[\"val_f1\"].append(val_f1)\n\n        print(f\"\\n{'='*60}\")\n        print(f\"Training Complete!\")\n        print(f\"Best Val F1: {best_val_f1:.4f}\")\n        print(f\"{'='*60}\\n\")\n\n        return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:40:35.676431Z","iopub.execute_input":"2025-11-27T07:40:35.676621Z","iopub.status.idle":"2025-11-27T07:40:35.712201Z","shell.execute_reply.started":"2025-11-27T07:40:35.676605Z","shell.execute_reply":"2025-11-27T07:40:35.711392Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Baseline Model","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nlabel_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")\nteacher_for_bilstm = QueryNERTeacher(\n    model_name=\"bert-base-uncased\",\n    label_info=label_info,\n    use_crf=False\n)\nteacher_for_bilstm.to(device)\n\nckpt_path = r\"/kaggle/input/teacher-processed-2e-5-nocrf-best/pytorch/default/1/teacher_processed_2e-5_nocrf_best.pt\"\nstate = torch.load(ckpt_path, map_location=device)  # state is likely a dict of tensors\n\nif all(isinstance(v, torch.Tensor) for v in state.values()):\n    teacher_for_bilstm.load_state_dict(state)\nelse:\n    if \"model_state_dict\" in state:\n        teacher_for_bilstm.load_state_dict(state[\"model_state_dict\"])\n    elif \"state_dict\" in state:\n        teacher_for_bilstm.load_state_dict(state[\"state_dict\"])\n    else:\n        for k, v in state.items():\n            if isinstance(v, dict) and any(isinstance(t, torch.Tensor) for t in v.values()):\n                teacher_for_bilstm.load_state_dict(v)\n                break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:16:55.924263Z","iopub.execute_input":"2025-11-22T11:16:55.924967Z","iopub.status.idle":"2025-11-22T11:16:56.886809Z","shell.execute_reply.started":"2025-11-22T11:16:55.924927Z","shell.execute_reply":"2025-11-22T11:16:56.885998Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\"\"\"\nComprehensive Baseline Training Script for NER Models\nTrains 4 models × 2 datasets × 3 learning rates × 2 CRF settings = 48 experiments\nWith Early Stopping and Best Model Checkpointing\n\"\"\"\n\nimport json\nimport os\nimport torch\nimport torch.optim as optim\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Import your existing modules (assumed to be available)\n# from your_module import (\n#     NERDataset, create_dataloaders, load_label_info,\n#     QueryNERTeacher, DistilBERTStudent, TinyBertStudent, BiLSTMStudent,\n#     KDTrainer\n# )\n\n\nclass EarlyStopping:\n    \"\"\"Early stopping to stop training when validation metric stops improving.\"\"\"\n    \n    def __init__(self, patience=3, min_delta=0.001, mode='max'):\n        \"\"\"\n        Args:\n            patience: Number of epochs to wait for improvement\n            min_delta: Minimum change to qualify as improvement\n            mode: 'max' for metrics like F1 (higher is better), 'min' for loss\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.mode = mode\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.best_epoch = 0\n        \n    def __call__(self, val_metric, epoch):\n        \"\"\"\n        Check if training should stop.\n        \n        Args:\n            val_metric: Current validation metric value\n            epoch: Current epoch number\n            \n        Returns:\n            bool: True if should stop, False otherwise\n        \"\"\"\n        score = val_metric\n        \n        if self.best_score is None:\n            self.best_score = score\n            self.best_epoch = epoch\n            return False\n        \n        # Check for improvement based on mode\n        if self.mode == 'max':\n            improved = score > self.best_score + self.min_delta\n        else:  # mode == 'min'\n            improved = score < self.best_score - self.min_delta\n        \n        if improved:\n            self.best_score = score\n            self.best_epoch = epoch\n            self.counter = 0\n        else:\n            self.counter += 1\n            print(f\"  EarlyStopping counter: {self.counter}/{self.patience}\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n                print(f\"  ✓ Early stopping triggered! Best epoch was {self.best_epoch}\")\n        \n        return self.early_stop\n\n\ndef create_experiment_config():\n    \"\"\"Generate all 48 experiment configurations\"\"\"\n    \n    # Configuration space\n    models = [\n        # (\"teacher\", \"QueryNERTeacher\", \"bert-base-uncased\"),\n        (\"distilbert\", \"DistilBERTStudent\", \"distilbert-base-uncased\"),\n        (\"tinybert\", \"TinyBertStudent\", \"huawei-noah/TinyBERT_General_4L_312D\"),\n        # (\"bilstm\", \"BiLSTMStudent\", \"bert-base-uncased\")\n    ]\n    \n    datasets = [\n        (\"processed\", {\n            \"train\": r\"/kaggle/input/queryner-dataset/data/processed/train.json\",\n            \"val\": r\"/kaggle/input/queryner-dataset/data/processed/validation.json\",\n            \"test\": r\"/kaggle/input/queryner-dataset/data/processed/test.json\"\n        })\n        # ,(\"raw\", {\n        #     \"train\": r\"/kaggle/input/queryner-dataset/data/raw/train.json\",\n        #     \"val\": r\"/kaggle/input/queryner-dataset/data/raw/validation.json\",\n        #     \"test\": r\"/kaggle/input/queryner-dataset/data/raw/test.json\"\n        # })\n    ]\n    \n    learning_rates = [\n        # (1e-5, \"1e-5\"),   # Very conservative\n        (2e-5, \"2e-5\"),   # Conservative, stable\n        # (5e-5, \"5e-5\")    # Balanced speed/stability\n\n        # for bilstm model trial\n        # (2e-4, \"2e-4\"),\n        # (5e-4, \"5e-4\"),\n        # (1e-3, \"1e-3\"),\n        # (2e-3, \"2e-3\"),\n        # (5e-3, \"5e-3\"),\n        # (1e-2, \"1e-2\")\n    ]\n    \n    crf_settings = [\n        (True, \"crf\"),\n        (False, \"nocrf\")\n    ]\n    \n    # Generate all combinations\n    experiments = []\n    exp_id = 1\n    \n    for model_name, model_class, model_path in models:\n        for data_name, data_paths in datasets:\n            for lr_value, lr_name in learning_rates:\n                for use_crf, crf_name in crf_settings:\n                    exp = {\n                        \"id\": exp_id,\n                        \"model_name\": model_name,\n                        \"model_class\": model_class,\n                        \"model_path\": model_path,\n                        \"data_name\": data_name,\n                        \"data_paths\": data_paths,\n                        \"learning_rate\": lr_value,\n                        \"lr_name\": lr_name,\n                        \"use_crf\": use_crf,\n                        \"crf_name\": crf_name,\n                        \"exp_name\": f\"{model_name}_{data_name}_{lr_name}_{crf_name}\"\n                    }\n                    experiments.append(exp)\n                    exp_id += 1\n    \n    return experiments\n\n\ndef evaluate_on_test(model, test_loader, device):\n    \"\"\"\n    Evaluate model on test set.\n    \n    Args:\n        model: Trained model (should be in eval mode)\n        test_loader: Test DataLoader\n        device: Device to use\n        \n    Returns:\n        test_loss, test_kd, test_stu, test_precision, test_recall, test_f1\n    \"\"\"\n    from tqdm.auto import tqdm\n    \n    model.eval()\n    total_loss = 0.0\n    tp_acc, pred_acc, actual_acc = 0, 0, 0\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Testing\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            batch_size, seq_len = input_ids.shape\n            \n            # Get model outputs\n            output = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            # Get loss\n            loss = output.get(\"loss\", torch.tensor(0.0, device=device))\n            total_loss += float(loss.item())\n            \n            # Get predictions\n            if \"pred\" in output:\n                pred = output[\"pred\"]\n                if isinstance(pred, torch.Tensor):\n                    pred_tensor = pred.to(device)\n                else:\n                    # Handle CRF list output\n                    pred_tensor = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n                    for i, p in enumerate(pred):\n                        if isinstance(p, torch.Tensor):\n                            p = p.tolist()\n                        L = len(p)\n                        if L > 0:\n                            pred_tensor[i, :L] = torch.tensor(p, dtype=torch.long, device=device)\n            else:\n                pred_tensor = output[\"logits\"].argmax(dim=-1)\n            \n            # Compute metrics\n            mask = attention_mask.bool()\n            valid = mask & (labels != -100)\n            \n            if valid.sum().item() > 0:\n                preds_flat = pred_tensor[valid].view(-1)\n                labels_flat = labels[valid].view(-1)\n                \n                # Compute TP, predicted, actual counts\n                tp = int((preds_flat == labels_flat).sum().item())\n                pred_count = int(preds_flat.numel())\n                actual_count = int(labels_flat.numel())\n                \n                tp_acc += tp\n                pred_acc += pred_count\n                actual_acc += actual_count\n    \n    # Compute averages\n    avg_loss = total_loss / len(test_loader)\n    \n    # Compute final metrics\n    precision = tp_acc / pred_acc if pred_acc > 0 else 0.0\n    recall = tp_acc / actual_acc if actual_acc > 0 else 0.0\n    if precision + recall > 0:\n        f1 = 2 * precision * recall / (precision + recall)\n    else:\n        f1 = 0.0\n    \n    return avg_loss, 0.0, avg_loss, precision, recall, f1\n\n\ndef instantiate_model(model_class, model_path, label_info, use_crf, device):\n    \"\"\"Instantiate the correct model based on class name\"\"\"\n    \n    if model_class == \"QueryNERTeacher\":\n        model = QueryNERTeacher(\n            model_name=model_path,\n            label_info=label_info,\n            use_crf=use_crf\n        )\n    elif model_class == \"DistilBERTStudent\":\n        model = DistilBERTStudent(\n            model_name=model_path,\n            label_info=label_info,\n            use_crf=use_crf\n        )\n    elif model_class == \"TinyBertStudent\":\n        model = TinyBertStudent(\n            model_name=model_path,\n            label_info=label_info,\n            use_crf=use_crf\n        )\n    elif model_class == \"BiLSTMStudent\":\n        model = BiLSTMStudent(\n            # num_labels=label_info[\"num_labels\"],\n            use_crf=use_crf,\n            model_name_for_vocab=model_path,\n            label_info=label_info,\n            teacher_model=teacher_for_bilstm\n        )\n    else:\n        raise ValueError(f\"Unknown model class: {model_class}\")\n    \n    return model.to(device)\n\n\ndef save_checkpoint(model, exp, epoch, val_f1, is_best=False):\n    \"\"\"\n    Save model checkpoint.\n    \n    Args:\n        model: Model to save\n        exp: Experiment configuration dict\n        epoch: Current epoch\n        val_f1: Validation F1 score\n        is_best: Whether this is the best model so far\n    \"\"\"\n    # Create checkpoints directory\n    checkpoint_dir = Path(\"/kaggle/working/checkpoints/baseline\")\n    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Prepare checkpoint data\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'val_f1': val_f1,\n        'experiment': exp\n    }\n    \n    # Save best model\n    if is_best:\n        best_path = checkpoint_dir / f\"{exp['exp_name']}_best.pt\"\n        torch.save(checkpoint, best_path)\n        print(f\"  ✓ Best model saved: {best_path}\")\n\n\ndef train_single_experiment(exp, label_info, device, num_epochs=15, batch_size=16, max_length=128, patience=3):\n    \"\"\"Train a single experiment configuration with early stopping\"\"\"\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"Experiment {exp['id']}/6: {exp['exp_name']}\")\n    print(f\"{'='*80}\")\n    print(f\"Model: {exp['model_name']}\")\n    print(f\"Dataset: {exp['data_name']}\")\n    print(f\"Learning Rate: {exp['lr_name']}\")\n    print(f\"CRF: {exp['use_crf']}\")\n    print(f\"Weight Decay: 0.01\")\n    print(f\"Early Stopping Patience: {patience}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Create dataloaders\n    print(\"Loading data...\")\n    train_loader, val_loader, test_loader = create_dataloaders(\n        train_path=exp['data_paths']['train'],\n        val_path=exp['data_paths']['val'],\n        test_path=exp['data_paths']['test'],\n        model_name=\"bert-base-uncased\",  # tokenizer\n        batch_size=batch_size,\n        max_length=max_length\n    )\n    \n    # Instantiate model\n    print(f\"Instantiating model: {exp['model_class']}...\")\n    model = instantiate_model(\n        model_class=exp['model_class'],\n        model_path=exp['model_path'],\n        label_info=label_info,\n        use_crf=exp['use_crf'],\n        device=device\n    )\n    \n    # Create optimizer with weight decay\n    optimizer = optim.AdamW(\n        model.parameters(), \n        lr=exp['learning_rate'], \n        weight_decay=0.01  # L2 regularization\n    )\n    \n    # Create early stopping\n    early_stopping = EarlyStopping(patience=patience, min_delta=0.001, mode='max')\n    \n    # Create trainer (using KD trainer with alpha=0, beta=1 for baseline)\n    trainer = KDTrainer(\n        teacher_model=None,  # No teacher for baseline\n        student_model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        optimizer=optimizer,\n        device=device,\n        alpha=0.0,  # No KD loss\n        beta=1.0,   # Only student loss\n        temperature=2.0  # Not used when alpha=0\n    )\n    \n    # Training loop with early stopping\n    print(f\"Training for up to {num_epochs} epochs (with early stopping)...\")\n    history = {\n        \"train_loss\": [], \"val_loss\": [],\n        \"train_kd\": [], \"val_kd\": [],\n        \"train_stu\": [], \"val_stu\": [],\n        \"train_precision\": [], \"train_recall\": [], \"train_f1\": [],\n        \"val_precision\": [], \"val_recall\": [], \"val_f1\": [],\n        \"test_loss\": None,\n        \"test_precision\": None,\n        \"test_recall\": None,\n        \"test_f1\": None,\n        \"stopped_epoch\": None,\n        \"best_epoch\": None\n    }\n    \n    best_val_f1 = 0.0\n    \n    for epoch in range(1, num_epochs + 1):\n        print(f\"\\n{'='*60}\")\n        print(f\"EPOCH {epoch}/{num_epochs}\")\n        print(f\"{'='*60}\")\n        \n        # Train and validate\n        train_loss, train_kd, train_stu, train_prec, train_rec, train_f1 = trainer.train_epoch()\n        val_loss, val_kd, val_stu, val_prec, val_rec, val_f1 = trainer.validate()\n        \n        print(f\"\\nTrain Loss: {train_loss:.4f} (KD: {train_kd:.4f}, Student: {train_stu:.4f})\")\n        print(f\"Val Loss:   {val_loss:.4f} (KD: {val_kd:.4f}, Student: {val_stu:.4f})\")\n        print(f\"\\nTrain Metrics -> P: {train_prec:.4f}, R: {train_rec:.4f}, F1: {train_f1:.4f}\")\n        print(f\"Val Metrics   -> P: {val_prec:.4f}, R: {val_rec:.4f}, F1: {val_f1:.4f}\")\n        \n        # Store history\n        history[\"train_loss\"].append(train_loss)\n        history[\"train_kd\"].append(train_kd)\n        history[\"train_stu\"].append(train_stu)\n        history[\"val_loss\"].append(val_loss)\n        history[\"val_kd\"].append(val_kd)\n        history[\"val_stu\"].append(val_stu)\n        history[\"train_precision\"].append(train_prec)\n        history[\"train_recall\"].append(train_rec)\n        history[\"train_f1\"].append(train_f1)\n        history[\"val_precision\"].append(val_prec)\n        history[\"val_recall\"].append(val_rec)\n        history[\"val_f1\"].append(val_f1)\n        \n        # Check if this is the best model\n        is_best = val_f1 > best_val_f1\n        if is_best:\n            best_val_f1 = val_f1\n            print(f\"  ✓ New best Val F1: {best_val_f1:.4f}\")\n            save_checkpoint(model, exp, epoch, val_f1, is_best=True)\n        \n        # Check early stopping\n        if early_stopping(val_f1, epoch):\n            history[\"stopped_epoch\"] = epoch\n            history[\"best_epoch\"] = early_stopping.best_epoch\n            print(f\"\\n{'='*60}\")\n            print(f\"Training stopped early at epoch {epoch}\")\n            print(f\"Best validation F1: {best_val_f1:.4f} at epoch {early_stopping.best_epoch}\")\n            print(f\"{'='*60}\")\n            break\n    else:\n        # Training completed without early stopping\n        history[\"stopped_epoch\"] = num_epochs\n        history[\"best_epoch\"] = history[\"val_f1\"].index(max(history[\"val_f1\"])) + 1\n        print(f\"\\n{'='*60}\")\n        print(f\"Training completed all {num_epochs} epochs\")\n        print(f\"Best validation F1: {best_val_f1:.4f} at epoch {history['best_epoch']}\")\n        print(f\"{'='*60}\")\n    \n    # Load best model checkpoint for test evaluation\n    print(f\"\\n{'='*60}\")\n    print(\"LOADING BEST MODEL FOR TEST EVALUATION\")\n    print(f\"{'='*60}\")\n    checkpoint_path = Path(\"/kaggle/working/checkpoints/baseline\") / f\"{exp['exp_name']}_best.pt\"\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    print(f\"✓ Loaded best model from epoch {checkpoint['epoch']} (Val F1: {checkpoint['val_f1']:.4f})\")\n    \n    # Evaluate on test set\n    print(f\"\\n{'='*60}\")\n    print(\"EVALUATING ON TEST SET\")\n    print(f\"{'='*60}\")\n    test_loss, test_kd, test_stu, test_prec, test_rec, test_f1 = evaluate_on_test(\n        model=model,\n        test_loader=test_loader,\n        device=device\n    )\n    \n    print(f\"\\nTest Results:\")\n    print(f\"  Loss: {test_loss:.4f}\")\n    print(f\"  Precision: {test_prec:.4f}\")\n    print(f\"  Recall: {test_rec:.4f}\")\n    print(f\"  F1: {test_f1:.4f}\")\n    \n    # Add test metrics to history\n    history[\"test_loss\"] = test_loss\n    history[\"test_precision\"] = test_prec\n    history[\"test_recall\"] = test_rec\n    history[\"test_f1\"] = test_f1\n    \n    # Save final results (now includes test metrics)\n    save_experiment_results(exp, history)\n    \n    # Clear memory\n    del model, trainer, optimizer, checkpoint\n    torch.cuda.empty_cache()\n    \n    return history\n\n\ndef save_experiment_results(exp, history):\n    \"\"\"Save experiment results in organized structure\"\"\"\n    \n    # Create directory structure\n    base_dir = Path(\"/kaggle/working/results/baseline\")\n    json_dir = base_dir / \"json\"\n    img_dir = base_dir / \"img\"\n    \n    json_dir.mkdir(parents=True, exist_ok=True)\n    img_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Save history as JSON\n    json_path = json_dir / f\"{exp['exp_name']}.json\"\n    \n    result_data = {\n        \"experiment\": exp,\n        \"history\": history,\n        \"timestamp\": datetime.now().isoformat()\n    }\n    \n    with open(json_path, \"w\") as f:\n        json.dump(result_data, f, indent=4)\n    \n    print(f\"\\n✓ Results saved to: {json_path}\")\n\n\ndef run_all_baselines(\n    device=\"cuda\",\n    num_epochs=15,\n    batch_size=16,\n    max_length=128,\n    patience=3,\n    start_from=1,\n    end_at=6\n):\n    \"\"\"Run all 48 baseline experiments with early stopping\"\"\"\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"BASELINE TRAINING: 48 EXPERIMENTS\")\n    print(\"=\"*80)\n    print(f\"Device: {device}\")\n    print(f\"Max Epochs: {num_epochs}\")\n    print(f\"Early Stopping Patience: {patience}\")\n    print(f\"Batch Size: {batch_size}\")\n    print(f\"Max Length: {max_length}\")\n    print(f\"Weight Decay: 0.01\")\n    print(f\"Dropout: 0.3 (in model definitions)\")\n    print(f\"Running experiments {start_from} to {end_at}\")\n    print(\"=\"*80 + \"\\n\")\n    \n    # Load label info (use teacher model config)\n    print(\"Loading label information...\")\n    label_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")\n    print(f\"Number of labels: {label_info['num_labels']}\")\n    \n    # Generate all experiment configs\n    experiments = create_experiment_config()\n    \n    # Filter experiments based on start_from and end_at\n    experiments = [exp for exp in experiments if start_from <= exp['id'] <= end_at]\n    \n    print(f\"\\nTotal experiments to run: {len(experiments)}\\n\")\n    \n    # Track results\n    all_results = []\n    failed_experiments = []\n    \n    # Run each experiment\n    for i, exp in enumerate(experiments, 1):\n        try:\n            history = train_single_experiment(\n                exp=exp,\n                label_info=label_info,\n                device=device,\n                num_epochs=num_epochs,\n                batch_size=batch_size,\n                max_length=max_length,\n                patience=patience\n            )\n            \n            # Store summary\n            final_metrics = {\n                \"exp_name\": exp['exp_name'],\n                \"val_f1\": history['val_f1'][-1],\n                \"val_precision\": history['val_precision'][-1],\n                \"val_recall\": history['val_recall'][-1],\n                \"best_val_f1\": max(history['val_f1']),\n                \"test_f1\": history['test_f1'],\n                \"test_precision\": history['test_precision'],\n                \"test_recall\": history['test_recall'],\n                \"best_epoch\": history['best_epoch'],\n                \"stopped_epoch\": history['stopped_epoch'],\n                \"early_stopped\": history['stopped_epoch'] < num_epochs\n            }\n            all_results.append(final_metrics)\n            \n            print(f\"\\n✓ Experiment {exp['id']} completed successfully!\")\n            print(f\"Best Val F1: {final_metrics['best_val_f1']:.4f} (epoch {final_metrics['best_epoch']})\")\n            print(f\"Test F1: {final_metrics['test_f1']:.4f}\")\n            print(f\"Stopped at epoch: {final_metrics['stopped_epoch']}\")\n            \n        except Exception as e:\n            print(f\"\\n✗ Experiment {exp['id']} FAILED!\")\n            print(f\"Error: {str(e)}\\n\")\n            failed_experiments.append({\n                \"exp_id\": exp['id'],\n                \"exp_name\": exp['exp_name'],\n                \"error\": str(e)\n            })\n            continue\n    \n    # Save summary\n    save_summary(all_results, failed_experiments)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"ALL EXPERIMENTS COMPLETED\")\n    print(\"=\"*80)\n    print(f\"Successful: {len(all_results)}\")\n    print(f\"Failed: {len(failed_experiments)}\")\n    print(\"=\"*80 + \"\\n\")\n\n\ndef save_summary(all_results, failed_experiments):\n    \"\"\"Save summary of all experiments\"\"\"\n    \n    summary_dir = Path(\"/kaggle/working/results/baseline\")\n    summary_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Save results summary\n    summary_path = summary_dir / \"summary.json\"\n    with open(summary_path, \"w\") as f:\n        json.dump({\n            \"successful_experiments\": all_results,\n            \"failed_experiments\": failed_experiments,\n            \"timestamp\": datetime.now().isoformat()\n        }, f, indent=4)\n    \n    print(f\"\\n✓ Summary saved to: {summary_path}\")\n    \n    # Print statistics\n    if all_results:\n        print(\"\\n\" + \"=\"*80)\n        print(\"TRAINING STATISTICS\")\n        print(\"=\"*80)\n        \n        # Early stopping stats\n        early_stopped = [r for r in all_results if r['early_stopped']]\n        print(f\"\\nEarly Stopping Statistics:\")\n        print(f\"  Experiments stopped early: {len(early_stopped)}/{len(all_results)}\")\n        if early_stopped:\n            avg_stopped = sum(r['stopped_epoch'] for r in early_stopped) / len(early_stopped)\n            print(f\"  Average stopping epoch: {avg_stopped:.1f}\")\n        \n        # Top performing models\n        print(\"\\n\" + \"=\"*80)\n        print(\"Top 10 Models by Best Val F1:\")\n        print(\"=\"*80)\n        sorted_results = sorted(all_results, key=lambda x: x['best_val_f1'], reverse=True)\n        for i, result in enumerate(sorted_results[:10], 1):\n            early_marker = \"⚡\" if result['early_stopped'] else \"  \"\n            print(f\"{i:2d}. {early_marker} {result['exp_name']:45s} | \"\n                  f\"Val F1: {result['best_val_f1']:.4f} | \"\n                  f\"Test F1: {result['test_f1']:.4f} | \"\n                  f\"Epoch: {result['best_epoch']:2d}/{result['stopped_epoch']:2d}\")\n        \n        # Best test F1 models\n        print(\"\\n\" + \"=\"*80)\n        print(\"Top 10 Models by Test F1:\")\n        print(\"=\"*80)\n        sorted_by_test = sorted(all_results, key=lambda x: x['test_f1'], reverse=True)\n        for i, result in enumerate(sorted_by_test[:10], 1):\n            early_marker = \"⚡\" if result['early_stopped'] else \"  \"\n            print(f\"{i:2d}. {early_marker} {result['exp_name']:45s} | \"\n                  f\"Test F1: {result['test_f1']:.4f} | \"\n                  f\"Val F1: {result['best_val_f1']:.4f}\")\n\n\ndef load_best_model(exp_name, model_class, model_path, label_info, device):\n    \"\"\"\n    Load the best saved model for an experiment.\n    \n    Args:\n        exp_name: Experiment name (e.g., \"distilbert_processed_2e-5_crf\")\n        model_class: Model class name\n        model_path: Path to pretrained model\n        label_info: Label information dict\n        device: Device to load model on\n        \n    Returns:\n        Loaded model with best weights\n    \"\"\"\n    # Find checkpoint file\n    checkpoint_dir = Path(\"/kaggle/working/checkpoints/baseline\")\n    checkpoint_path = checkpoint_dir / f\"{exp_name}_best.pt\"\n    \n    if not checkpoint_path.exists():\n        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n    \n    # Load checkpoint\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    \n    # Get use_crf from experiment config\n    use_crf = checkpoint['experiment']['use_crf']\n    \n    # Instantiate model\n    model = instantiate_model(model_class, model_path, label_info, use_crf, device)\n    \n    # Load weights\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    print(f\"✓ Loaded best model from epoch {checkpoint['epoch']}\")\n    print(f\"  Val F1: {checkpoint['val_f1']:.4f}\")\n    \n    return model\n\n\n# Example usage\nif __name__ == \"__main__\":\n    # Check device\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Using device: {device}\")\n    \n    # Run all baselines with early stopping\n    # You can also run in batches:\n    # run_all_baselines(device=device, start_from=1, end_at=12)   # First 12\n    # run_all_baselines(device=device, start_from=13, end_at=24)  # Next 12\n    # run_all_baselines(device=device, start_from=25, end_at=36)  # Next 12\n    # run_all_baselines(device=device, start_from=37, end_at=48)  # Last 12\n    \n    run_all_baselines(\n        device=device,\n        num_epochs=15,      # Max epochs (will stop early if no improvement)\n        batch_size=32,\n        max_length=128,\n        patience=3,         # Stop if no improvement for 3 epochs\n        start_from=1,\n        end_at=4\n    )\n    \n    # Example: Load best model after training\n    # label_info = load_label_info(\"bltlab/queryner-augmented-data-bert-base-uncased\")\n    # best_model = load_best_model(\n    #     exp_name=\"distilbert_processed_2e-5_crf\",\n    #     model_class=\"DistilBERTStudent\",\n    #     model_path=\"distilbert-base-uncased\",\n    #     label_info=label_info,\n    #     device=device\n    # )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T07:42:31.317749Z","iopub.execute_input":"2025-11-27T07:42:31.318070Z","iopub.status.idle":"2025-11-27T08:10:27.909373Z","shell.execute_reply.started":"2025-11-27T07:42:31.318047Z","shell.execute_reply":"2025-11-27T08:10:27.908388Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\n================================================================================\nBASELINE TRAINING: 48 EXPERIMENTS\n================================================================================\nDevice: cuda\nMax Epochs: 10\nEarly Stopping Patience: 2\nBatch Size: 16\nMax Length: 128\nWeight Decay: 0.01\nDropout: 0.3 (in model definitions)\nRunning experiments 1 to 2\n================================================================================\n\nLoading label information...\nNumber of labels: 35\n\nTotal experiments to run: 1\n\n\n================================================================================\nExperiment 1/6: teacher_processed_2e-5_nocrf\n================================================================================\nModel: teacher\nDataset: processed\nLearning Rate: 2e-5\nCRF: False\nWeight Decay: 0.01\nEarly Stopping Patience: 2\n================================================================================\n\nLoading data...\nInstantiating model: QueryNERTeacher...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ea0b5dcf5245f795150d99f6686a33"}},"metadata":{}},{"name":"stdout","text":"\n============================================================\nTraining Mode: BASELINE\nAlpha (KD loss weight): 0.0\nBeta (Student loss weight): 1.0\nTemperature: 2.0\n============================================================\n\nTraining for up to 10 epochs (with early stopping)...\n\n============================================================\nEPOCH 1/10\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3578fa67223a4a42b1c18f00b5766686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db485c9c7ba40f4bc7919f21f4b1139"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 1.4370 (KD: 0.0000, Student: 1.4370)\nVal Loss:   0.9554 (KD: 0.0000, Student: 0.9554)\n\nTrain Metrics -> P: 0.5927, R: 0.5927, F1: 0.5927\nVal Metrics   -> P: 0.7221, R: 0.7221, F1: 0.7221\n  ✓ New best Val F1: 0.7221\n  ✓ Best model saved: /kaggle/working/checkpoints/baseline/teacher_processed_2e-5_nocrf_best.pt\n\n============================================================\nEPOCH 2/10\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7b6f90eb1dd4c57aea50f99f2eba838"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d7f40f876c46f8a77293fbc2f458c3"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.8219 (KD: 0.0000, Student: 0.8219)\nVal Loss:   0.9059 (KD: 0.0000, Student: 0.9059)\n\nTrain Metrics -> P: 0.7552, R: 0.7552, F1: 0.7552\nVal Metrics   -> P: 0.7348, R: 0.7348, F1: 0.7348\n  ✓ New best Val F1: 0.7348\n  ✓ Best model saved: /kaggle/working/checkpoints/baseline/teacher_processed_2e-5_nocrf_best.pt\n\n============================================================\nEPOCH 3/10\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c32867dd8549fba6b432c5c96472a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b5147e4cfc46a7be2368f88ae16017"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.5602 (KD: 0.0000, Student: 0.5602)\nVal Loss:   0.9068 (KD: 0.0000, Student: 0.9068)\n\nTrain Metrics -> P: 0.8310, R: 0.8310, F1: 0.8310\nVal Metrics   -> P: 0.7414, R: 0.7414, F1: 0.7414\n  ✓ New best Val F1: 0.7414\n  ✓ Best model saved: /kaggle/working/checkpoints/baseline/teacher_processed_2e-5_nocrf_best.pt\n\n============================================================\nEPOCH 4/10\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e505a27df7fa4c18bec3c4814c4e3492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/55 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7f72120f06c4b269e9a5c7e3c30f0f5"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.3716 (KD: 0.0000, Student: 0.3716)\nVal Loss:   1.0042 (KD: 0.0000, Student: 1.0042)\n\nTrain Metrics -> P: 0.8922, R: 0.8922, F1: 0.8922\nVal Metrics   -> P: 0.7427, R: 0.7427, F1: 0.7427\n  ✓ New best Val F1: 0.7427\n  ✓ Best model saved: /kaggle/working/checkpoints/baseline/teacher_processed_2e-5_nocrf_best.pt\n\n============================================================\nEPOCH 5/10\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceaf89355b2743ff9e4eca58a0ad4422"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2933947444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;31m# run_all_baselines(device=device, start_from=37, end_at=48)  # Last 12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     run_all_baselines(\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Max epochs (will stop early if no improvement)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2933947444.py\u001b[0m in \u001b[0;36mrun_all_baselines\u001b[0;34m(device, num_epochs, batch_size, max_length, patience, start_from, end_at)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             history = train_single_experiment(\n\u001b[0m\u001b[1;32m    540\u001b[0m                 \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mlabel_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2933947444.py\u001b[0m in \u001b[0;36mtrain_single_experiment\u001b[0;34m(exp, label_info, device, num_epochs, batch_size, max_length, patience)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Train and validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_stu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_kd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_stu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2275498187.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mtotal_kd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_kd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtotal_stu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_student\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16}]}